{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "import time\n",
    "from graph_tool.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data information:\n",
    "\n",
    "* rasterwgs84 is 976, 1760, main folder is ca 2500x3000\n",
    "\n",
    "np.mgrid might be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_files = \"../../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_tifs(path):\n",
    "    files = os.listdir(path)\n",
    "    tif_list = []\n",
    "    file_list = []\n",
    "    for f in files:\n",
    "        if f[-3:]==\"tif\":\n",
    "            img = Image.open(os.path.join(path,f))\n",
    "            tif_list.append(np.array(img))\n",
    "            file_list.append(f[:-4])\n",
    "    tif_arr = np.array(tif_list)\n",
    "    tif_arr = tif_arr/255.\n",
    "    print(\"shape of tif array:\", tif_arr.shape)\n",
    "    return tif_arr, file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tifs, files = read_in_tifs(path_files)\n",
    "plt.imshow(tifs[8,:,:])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corridor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corridor(path, fn = \"Corridor_BE.tif\"):\n",
    "    with rasterio.open(os.path.join(path,fn), 'r') as ds:\n",
    "        arr = ds.read() \n",
    "    corr_img = Image.fromarray(arr[0])\n",
    "    corr_resized = corr_img.resize((3022, 2627),resample=Image.BILINEAR)\n",
    "    corridor = (np.array(corr_resized)<9900).astype(int)\n",
    "    # plt.imshow(corridor)\n",
    "    # plt.colorbar()\n",
    "    # plt.show()\n",
    "    return corridor\n",
    "\n",
    "def normalize(instance):\n",
    "    return (instance -\n",
    "            np.min(instance)) / (np.max(instance) - np.min(instance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corridor = get_corridor(os.path.join(path_files, \"corridor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cost surface\n",
    "with rasterio.open(os.path.join(path_files, \"corridor/COSTSURFACE.tif\"), 'r') as ds:\n",
    "    arr = ds.read() \n",
    "print(arr.shape)\n",
    "costs = normalize(arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(costs)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other hard constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_cons_path = os.path.join(path_files, \"hard_constraints\")\n",
    "hard_cons_arr, files = read_in_tifs(hard_cons_path)\n",
    "# add corridor\n",
    "hard_cons_arr = np.concatenate((hard_cons_arr, np.expand_dims(corridor, axis=0)), axis=0)\n",
    "print(hard_cons_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logical and between all hard constraints\n",
    "hard_constraints = np.all(hard_cons_arr.astype(int), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hard_constraints)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum tifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed = np.sum(tifs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(summed)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define circle coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_donut(radius_low, radius_high):\n",
    "    img_size = int(radius_high + 10)\n",
    "    # xx and yy are 200x200 tables containing the x and y coordinates as values\n",
    "    # mgrid is a mesh creation helper\n",
    "    xx, yy = np.mgrid[-img_size:img_size, -img_size:img_size]\n",
    "    # circle equation\n",
    "    circle = (xx) ** 2 + (yy) ** 2\n",
    "    # donuts contains 1's and 0's organized in a donut shape\n",
    "    # you apply 2 thresholds on circle to define the shape\n",
    "    donut = np.logical_and(circle < (radius_high**2), circle > (radius_low**2))\n",
    "    pos_x, pos_y = np.where(donut>0)\n",
    "    return pos_x-img_size, pos_y-img_size\n",
    "\n",
    "def get_half_donut(radius_low, radius_high, vec):\n",
    "    pos_x, pos_y = get_donut(radius_low, radius_high)\n",
    "    new_tuples = []\n",
    "    # vector = np.asarray(vec)\n",
    "    # vector = vector/np.linalg.norm(vector)\n",
    "    for i, j in zip(pos_x, pos_y):\n",
    "        if i*vec[0] + j*vec[1] >=0:\n",
    "        # point = np.asarray([i,j]).T\n",
    "        # if np.dot(point)>0:\n",
    "        # if i>0 or (i==0 and j>0):\n",
    "            new_tuples.append((i,j))\n",
    "    return new_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example:\n",
    "upper = 5.5\n",
    "img_size = int(upper)+1\n",
    "pos_x, pos_y = get_donut(2.5,upper)\n",
    "\n",
    "# new donut\n",
    "new_tuples =  get_half_donut(2.5,upper, (-1,1))\n",
    "print(new_tuples)\n",
    "\n",
    "# whole donut\n",
    "ar = np.zeros((2*img_size,2*img_size))\n",
    "for i in range(len(pos_x)):\n",
    "    ar[pos_x[i]+img_size, pos_y[i]+img_size]=1\n",
    "plt.imshow(ar)\n",
    "plt.show()\n",
    "\n",
    "# modified donut\n",
    "ar = np.zeros((2*img_size,2*img_size))\n",
    "for tup in new_tuples:\n",
    "    ar[tup[0]+img_size, tup[1]+img_size]=1\n",
    "plt.imshow(ar)\n",
    "plt.show()\n",
    "print(len(new_tuples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale down instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_instance(summed, square):\n",
    "    x_len,y_len = summed.shape\n",
    "    new_img = np.zeros((x_len//square, y_len//square))\n",
    "    for i in range(x_len//square):\n",
    "        for j in range(y_len//square):\n",
    "            patch = summed[i*square:(i+1)*square, j*square:(j+1)*square]\n",
    "            new_img[i,j] = np.mean(patch)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = reduce_instance(summed, 16)\n",
    "instance_norm = (instance-np.min(instance))/(np.max(instance)-np.min(instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(instance_norm)\n",
    "# plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_corr = reduce_instance(hard_constraints, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(instance_corr)\n",
    "# plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networkx graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos2node(pos, length):\n",
    "    return pos[0]*length + pos[1]\n",
    "def node2pos(node, length):\n",
    "    j = node%length # rest\n",
    "    i = node//length\n",
    "    return i,j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_x, pos_y = get_donut(2.5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_list = [\"{},{}\".format(str(i), str(i)) for i in range(10)] # with strings\n",
    "x_len, y_len = instance_norm.shape\n",
    "print(x_len, y_len)\n",
    "node_list = [(pos2node((i,j), y_len),{\"pos\":(i,j)}) for i in range(x_len) for j in range(y_len) if instance_corr[i,j]]\n",
    "# assert len(np.unique([n[0] for n in node_list]))==x_len*y_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list_wo_attr = [n[0] for n in node_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "inds_x, inds_y = np.where(instance_corr>0)\n",
    "donut_tuples = get_half_donut(2.5,5)\n",
    "edge_list = []\n",
    "\n",
    "for i, j in zip(inds_x, inds_y):\n",
    "    weight_node = 1-instance_norm[i,j]\n",
    "    node_name = pos2node((i,j), y_len)\n",
    "    for (x,y) in donut_tuples:\n",
    "        new_x = i+x\n",
    "        new_y = j+y\n",
    "        if new_x>=0 and new_x<x_len and new_y>=0 and new_y<y_len and instance_corr[new_x,new_y]: # inside corridor\n",
    "            weight = 1-instance_norm[new_x, new_y]+weight_node\n",
    "            edge_list.append((node_name, pos2node((new_x,new_y), y_len), {\"weight\": round(weight,1)}))\n",
    "            \n",
    "print(time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(edge_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add edges and nodes to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "g.add_nodes_from(node_list)\n",
    "g.add_edges_from(edge_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the graph with edge attributes etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(g):\n",
    "    labels = nx.get_edge_attributes(g,'weight') # returns dictionary\n",
    "    pos = nx.get_node_attributes(g,'pos')\n",
    "    plt.figure(figsize=(20,10))\n",
    "    nx.draw(g,pos)\n",
    "    nx.draw_networkx_edge_labels(g, pos, edge_labels=labels)\n",
    "    # plt.savefig(\"first_graph.png\")\n",
    "    plt.show()\n",
    "plot_graph(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run shortest path algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_node = 9 # node_list[0][0]\n",
    "last_node = 277 # node_list[-1][0]\n",
    "path = nx.bellman_ford_path(g,first_node, last_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_positions = [node2pos(v, y_len) for v in path]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path(instance, path):\n",
    "    # expand to greyscale\n",
    "    expanded = np.expand_dims(instance, axis=2)\n",
    "    expanded = np.tile(expanded, (1,1,3)) # overwrite instance by tiled one\n",
    "    # colour nodes in path in red\n",
    "    for (x,y) in path:\n",
    "        expanded[x,y] = [0.9, 0.2, 0.2]\n",
    "        \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(expanded)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Tools version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define node to pos and pos to node mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new version: node - pos list and pos -> node dictionary\n",
    "x_len, y_len = instance_norm.shape\n",
    "\n",
    "node_pos = [(i,j) for i in range(x_len) for j in range(y_len) if instance_corr[i,j]]\n",
    "pos_node = {node_pos[i]:i for i in range(len(node_pos))}\n",
    "\n",
    "pos2node = np.ones(instance_norm.shape)\n",
    "pos2node *= -1\n",
    "for n, (i,j) in enumerate(node_pos):\n",
    "    pos2node[i,j] = n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define graph and add nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "\n",
    "G = Graph(directed=False)\n",
    "weight = G.new_edge_property(\"float\")\n",
    "\n",
    "# add nodes to graph\n",
    "vlist = G.add_vertex(len(node_pos))\n",
    "print(\"added nodes:\", len(list(vlist)))\n",
    "\n",
    "print(\"time to add nodes to graph\", time.time()-tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add edges: new version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_surface_general(costs, shift):\n",
    "    if shift[0]<0:\n",
    "        tup1 = (0,-shift[0])\n",
    "    else:\n",
    "        tup1 = (shift[0],0)\n",
    "    if shift[1]<0:\n",
    "        tup2 = (0,-shift[1])\n",
    "    else:\n",
    "        tup2 = (shift[1],0)\n",
    "        \n",
    "    costs_shifted = np.pad(costs, (tup1,tup2), mode='constant')\n",
    "    \n",
    "    if shift[0]>0 and shift[1]>0:\n",
    "        costs_shifted = costs_shifted[:-shift[0], :-shift[1]]\n",
    "    elif shift[0]>0 and shift[1]<=0:\n",
    "        costs_shifted = costs_shifted[:-shift[0], -shift[1]:]\n",
    "    elif shift[0]<=0 and shift[1]>0:\n",
    "        costs_shifted = costs_shifted[-shift[0]:, :-shift[1]]\n",
    "    elif shift[0]<=0 and shift[1]<=0:\n",
    "        costs_shifted = costs_shifted[-shift[0]:, -shift[1]:]\n",
    "        \n",
    "    return costs_shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_surface(costs, shift):\n",
    "    rolled_costs = np.roll(costs, shift, axis=(0,1))\n",
    "    rolled_costs[:shift[0], :] = 0\n",
    "    if shift[1] >= 0:\n",
    "        rolled_costs[:, :shift[1]] = 0\n",
    "    else:\n",
    "        rolled_costs[:, shift[1]:] = 0\n",
    "    return rolled_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.linspace(0,1,81).reshape((9,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_surface(arr, (1,-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_surface_general(arr, (1,-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For testing --> delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bresenham_line(x0, y0, x1, y1):\n",
    "    \"\"\"\n",
    "    find pixels on line between two pixels\n",
    "    https://stackoverflow.com/questions/50995499/generating-pixel-values-of-line-connecting-2-points\n",
    "\n",
    "    \"\"\"\n",
    "    steep = abs(y1 - y0) > abs(x1 - x0)\n",
    "    if steep:\n",
    "        x0, y0 = y0, x0\n",
    "        x1, y1 = y1, x1\n",
    "\n",
    "    switched = False\n",
    "    if x0 > x1:\n",
    "        switched = True\n",
    "        x0, x1 = x1, x0\n",
    "        y0, y1 = y1, y0\n",
    "\n",
    "    if y0 < y1:\n",
    "        ystep = 1\n",
    "    else:\n",
    "        ystep = -1\n",
    "\n",
    "    deltax = x1 - x0\n",
    "    deltay = abs(y1 - y0)\n",
    "    error = -deltax / 2\n",
    "    y = y0\n",
    "\n",
    "    line = []\n",
    "    for x in range(x0, x1 + 1):\n",
    "        if steep:\n",
    "            line.append([y, x])\n",
    "        else:\n",
    "            line.append([x, y])\n",
    "\n",
    "        error = error + deltay\n",
    "        if error > 0:\n",
    "            y = y + ystep\n",
    "            error = error - deltax\n",
    "    if switched:\n",
    "        line.reverse()\n",
    "    return line\n",
    "\n",
    "\n",
    "def get_kernel(shifts):\n",
    "    \"\"\"\n",
    "    Get all kernels describing the path of the edges in a discrete raster\n",
    "    :param shifts: possible circle points\n",
    "    :returns kernel: all possible kernels (number of circle points x upper x upper)\n",
    "    :returns posneg: a list indicating whether it is a path to the left (=1) or to the right(=0)\n",
    "    \"\"\"\n",
    "    upper = np.amax(np.absolute(shifts)) + 1\n",
    "    posneg = []\n",
    "    kernel = np.zeros((len(shifts), upper, upper))\n",
    "\n",
    "    for i, shift in enumerate(shifts):\n",
    "        if shift[1] < 0:\n",
    "            posneg.append(1)\n",
    "            line = bresenham_line(0, upper - 1, shift[0], upper - 1 + shift[1])\n",
    "        else:\n",
    "            posneg.append(0)\n",
    "            line = bresenham_line(0, 0, shift[0], shift[1])\n",
    "        # add points of line to the kernel\n",
    "        for (j, k) in line:\n",
    "            kernel[i, j, k] += 1\n",
    "    return kernel, posneg\n",
    "\n",
    "\n",
    "def convolve(img, kernel, neg=0):\n",
    "    k_size = len(kernel)\n",
    "    if neg:\n",
    "        padded = np.pad(img, ((0, k_size - 1), (k_size - 1, 0)))\n",
    "    else:\n",
    "        padded = np.pad(img, ((0, k_size), (0, k_size)))\n",
    "    # print(padded.shape)\n",
    "    convolved = np.zeros(img.shape)\n",
    "    w, h = img.shape\n",
    "    for i in range(0, w):\n",
    "        for j in range(0, h):\n",
    "            patch = padded[i:i + k_size, j:j + k_size]\n",
    "            convolved[i, j] = np.sum(patch * kernel)\n",
    "    return convolved\n",
    "\n",
    "def shift_surface(costs, shift):\n",
    "    rolled_costs = np.roll(costs, shift, axis=(0, 1))\n",
    "    rolled_costs[:shift[0], :] = 0\n",
    "    if shift[1] >= 0:\n",
    "        rolled_costs[:, :shift[1]] = 0\n",
    "    else:\n",
    "        rolled_costs[:, shift[1]:] = 0\n",
    "    return rolled_costs\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "G = Graph(directed=False)\n",
    "weight = G.new_edge_property(\"float\")\n",
    "\n",
    "# add nodes to graph\n",
    "vlist = G.add_vertex(len(node_pos))\n",
    "print(\"added nodes:\", len(list(vlist)))\n",
    "\n",
    "print(\"time to add nodes to graph\", time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# umdefinitions of variables\n",
    "costs = 1-instance_norm\n",
    "corrgreater0 = (instance_corr>0).astype(int)\n",
    "costs_rest = costs*corrgreater0\n",
    "# plt.imshow(costs*corrgreater0)\n",
    "# plt.show()\n",
    "shifts = donut_tuples\n",
    "\n",
    "orig_greater_zero = costs_rest>0\n",
    "inds_orig = pos2node[costs_rest>0]\n",
    "\n",
    "kernels, posneg = get_kernel(shifts)\n",
    "\n",
    "for i in range(len(shifts)):\n",
    "    # print(shifts[i], shift_tuples[i])\n",
    "    costs_shifted = shift_surface(costs_rest, shifts[i])\n",
    "    \n",
    "    # both_greater_zero = np.all(np.asarray([orig_greater_zero, costs_shifted>0]), axis=0)\n",
    "    # weights = (costs_shifted + costs_rest)/2\n",
    "    weights = convolve(costs_rest, kernels[i], posneg[i])\n",
    "    \n",
    "    inds_shifted = pos2node[costs_shifted>0]\n",
    "    # delete the ones where inds_shifted is zero\n",
    "    assert len(inds_shifted)==len(inds_orig)\n",
    "    weights_list = weights[costs_shifted>0]\n",
    "    \n",
    "    pos_inds = inds_shifted>=0\n",
    "    out = np.swapaxes(np.asarray([inds_orig, inds_shifted, weights_list]), 1,0)[pos_inds]\n",
    "    # print(out.shape)\n",
    "    # print(out[:100])\n",
    "    G.add_edge_list(out, eprops=[weight])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add edges: old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "# inds_x, inds_y = np.where(instance_corr>0)\n",
    "donut_tuples = get_half_donut(2.5,5)\n",
    "edge_list = []\n",
    "\n",
    "for n, (i, j) in enumerate(node_pos):\n",
    "    # n is the name of the node in the graph (=index), (i,j) the position\n",
    "    weight_node = 1-instance_norm[i,j]\n",
    "    for (x,y) in donut_tuples:\n",
    "        new_x = i+x\n",
    "        new_y = j+y\n",
    "        if new_x>=0 and new_x<x_len and new_y>=0 and new_y<y_len and instance_corr[new_x,new_y]: # inside corridor\n",
    "            weight = 1-instance_norm[new_x, new_y]+weight_node\n",
    "            edge_list.append([n, pos_node[(new_x,new_y)], round(weight,3)])\n",
    "            \n",
    "print(\"time to build edge list\", time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "\n",
    "# add edges and properties to the graph\n",
    "G.add_edge_list(edge_list, eprops=[weight])\n",
    "print(\"added edges:\", len(list(G.edges())))\n",
    "\n",
    "print(\"time to add edges and nodes to graph\", time.time()-tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add start and end vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_start_end_vertices(G, instance_corr, pos2node, start_list=None, end_list=None):\n",
    "    # defaults if no start and end list are given:\n",
    "    topbottom, leftright = np.where(instance_corr) # change \n",
    "    if start_list is None:\n",
    "        nr_start = len(topbottom)//100\n",
    "        start_list = zip(topbottom[:nr_start], leftright[:nr_start])\n",
    "    if end_list is None:\n",
    "        nr_end = len(topbottom)//100\n",
    "        end_list = zip(topbottom[-nr_end:], leftright[-nr_end:])\n",
    "        \n",
    "    neighbor_lists = [start_list, end_list]\n",
    "    start_and_end = []\n",
    "\n",
    "    for k in [0,1]:\n",
    "        v = G.add_vertex()\n",
    "        v_index = G.vertex_index[v]\n",
    "        start_and_end.append(v)\n",
    "        print(\"index of start/end vertex\", v_index)\n",
    "        edges = []\n",
    "        for (i,j) in neighbor_lists[k]:\n",
    "            neighbor_ind = pos2node[i,j]\n",
    "            edges.append([v_index, neighbor_ind, 0])\n",
    "        G.add_edge_list(edges, eprops=[weight])\n",
    "    \n",
    "    return start_and_end\n",
    "\n",
    "add_start_end_vertices(G, instance_corr, pos2node, start_list=None, end_list=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute shortest path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = (time.time())\n",
    "source = 7075\n",
    "target = 7076\n",
    "vertices_path, edges_path = shortest_path(G, G.vertex(source), G.vertex(target), weights=weight, negative_weights=True) # true for bellman ford\n",
    "gt_path = [node_pos[G.vertex_index[v]] for v in vertices_path[1:-1]]\n",
    "print(\"time for shortest path\", time.time()-tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track why edges costs path take so many turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in G.vertex(vertices_path[1]).out_edges():\n",
    "    print(e)\n",
    "    print(G.ep.weight[e])\n",
    "    \n",
    "for e in edges_path:\n",
    "    print(G.ep.weight[e])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path(instance, path):\n",
    "    # expand to greyscale\n",
    "    expanded = np.expand_dims(instance, axis=2)\n",
    "    expanded = np.tile(expanded, (1,1,3)) # overwrite instance by tiled one\n",
    "    # colour nodes in path in red\n",
    "    for (x,y) in path:\n",
    "        \n",
    "        expanded[x-2:x+2,y-2:y+2] = [0.9, 0.2, 0.2]\n",
    "        \n",
    "    plt.figure(figsize=(25,15))\n",
    "    plt.imshow(expanded)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path(instance_norm, gt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to have internal property map https://graph-tool.skewed.de/static/doc/quickstart.html#internal-property-maps\n",
    "G.edge_properties[\"weight\"] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.save(\"my_graph.xml.gz\")\n",
    "print(weight[G.edge(66, 69)]) # error because weight also used as variable in edge_list definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G2 = load_graph(\"my_graph.xml.gz\")\n",
    "weight = G2.ep.weight[G2.edge(66, 69)]\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_mapping = G2.ep.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shift_transformed(shifts):\n",
    "    \n",
    "    shift_tuples = []\n",
    "    for shift in shifts:\n",
    "        if shift[0]<0:\n",
    "            tup1 = (0,-shift[0])\n",
    "        else:\n",
    "            tup1 = (shift[0],0)\n",
    "        if shift[1]<0:\n",
    "            tup2 = (0,-shift[1])\n",
    "        else:\n",
    "            tup2 = (shift[1],0)\n",
    "        shift_tuples.append((tup1,tup2))\n",
    "    \n",
    "    return shift_tuples\n",
    "\n",
    "donut_tuples = get_half_donut(2.5,5)\n",
    "shift_tuples = get_shift_transformed(donut_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old version to add edges to gt graph\n",
    "for edge in edge_list:\n",
    "    e = G.add_edge(edge[0], edge[1])\n",
    "    weight[e] = edge[2][\"weight\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old version to form edge list\n",
    "edge_list = []\n",
    "for i in range(x_len):\n",
    "    for j in range(y_len):\n",
    "        node_name = pos2node((i,j), y_len)\n",
    "        if node_name in node_list_wo_attr:\n",
    "            weight_node = 1-instance_norm[i,j]\n",
    "            for x,y in zip(pos_x, pos_y):\n",
    "                new_x = i+x\n",
    "                new_y = j+y\n",
    "                if new_x>=0 and new_x<x_len and new_y>=0 and new_y<y_len and instance_corr[new_x,new_y]: # inside corridor\n",
    "                    weight = 1-instance_norm[new_x, new_y]+weight_node\n",
    "                    edge_list.append((node_name, pos2node((new_x,new_y), y_len), {\"weight\": round(weight,1)}))\n",
    "                    # TODO: INVERT edge weight\n",
    "                    \n",
    "\n",
    "                    \n",
    "# FROM MAIN PY FILE:\n",
    "\n",
    "tic = time.time()\n",
    "# inds_x, inds_y = np.where(instance_corr>0)\n",
    "donut_tuples = get_half_donut(2.5, 5)\n",
    "edge_list = []\n",
    "for n, (i, j) in enumerate(node_pos):\n",
    "    # n is the name of the node in the graph (=index), (i,j) the position\n",
    "    weight_node = 1 - instance_norm[i, j]\n",
    "    for (x, y) in donut_tuples:\n",
    "        new_x = i + x\n",
    "        new_y = j + y\n",
    "        # if inside the image at all\n",
    "        if new_x >= 0 and new_x < x_len and new_y >= 0 and new_y < y_len:\n",
    "            # if inside corridor\n",
    "            if instance_corr[new_x, new_y]:\n",
    "                weight = 1 - instance_norm[new_x, new_y] + weight_node\n",
    "                edge_list.append(\n",
    "                    (\n",
    "                        n, pos_node[(new_x, new_y)], {\n",
    "                            \"weight\": round(weight, 3)\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "print(\"time to build edge list:\", time.time() - tic)\n",
    "\n",
    "# construct graph\n",
    "tic = (time.time())\n",
    "G = Graph(directed=False)\n",
    "weight = G.new_edge_property(\"float\")\n",
    "vlist = G.add_vertex(len(node_pos))  # nodes: indices of node_list\n",
    "print(\"added nodes:\", len(list(vlist)))\n",
    "for edge in edge_list:\n",
    "    e = G.add_edge(edge[0], edge[1])\n",
    "    weight[e] = edge[2][\"weight\"]\n",
    "print(\"time to build up the graph:\", time.time() - tic)\n",
    "\n",
    "# get shortest path\n",
    "tic = (time.time())\n",
    "SOURCE = 0\n",
    "TARGET = len(node_pos) - 1\n",
    "vertices_path, edges_path = shortest_path(\n",
    "    G,\n",
    "    G.vertex(SOURCE),\n",
    "    G.vertex(TARGET),\n",
    "    weights=weight,\n",
    "    negative_weights=True\n",
    ")  # true for bellman ford\n",
    "path = [node_pos[G.vertex_index[v]] for v in vertices_path]\n",
    "print(\"time for shortest path\", time.time() - tic)\n",
    "\n",
    "# new version: node - pos list and pos -> node dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [(1,2), (3.4, 5.5)]\n",
    "import json\n",
    "with open(\"test.json\", \"w\") as outfile:\n",
    "    json.dump(l, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.json\", \"r\") as outfile:\n",
    "    l_new = json.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
