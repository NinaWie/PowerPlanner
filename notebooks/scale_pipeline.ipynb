{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from power_planner.utils.utils import get_donut_vals, get_half_donut, get_distance_surface, bresenham_line\n",
    "from power_planner.utils.utils_constraints import ConstraintUtils\n",
    "from power_planner.plotting import plot_path, plot_path_costs\n",
    "import numpy as np\n",
    "from graph_tool.all import Graph, shortest_path,load_graph, find_edge, remove_labeled_edges\n",
    "import time\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from skimage.segmentation import watershed\n",
    "from skimage import data, util, filters, color\n",
    "from power_planner.utils.utils_costs import CostUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_path = \"../data/data_dump_1.dat\"\n",
    "with open(instance_path, \"rb\") as infile:\n",
    "    data = pickle.load(infile)\n",
    "(instance, instance_corr, start_inds, dest_inds) = data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DATA DUMP 2\n",
    "LAYER_CLASSES = ['cultural', 'human', 'planning', 'technical']\n",
    "CLASS_WEIGHT = [0.28571429, 0.35714286, 0.14285714, 0.21428571]\n",
    "PYLON_DIST_MIN = 7.5\n",
    "PYLON_DIST_MAX = 12.5\n",
    "vec = [-69, 216]\n",
    "MAX_ANGLE = 0.5 * np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DATA DUMP 5\n",
    "LAYER_CLASSES = ['cultural', 'human', 'planning', 'technical']\n",
    "CLASS_WEIGHT = [0.28571429, 0.35714286, 0.14285714, 0.21428571]\n",
    "PYLON_DIST_MIN = 3\n",
    "PYLON_DIST_MAX = 5\n",
    "vec = [-69, 216]\n",
    "MAX_ANGLE = 0.5 * np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../outputs/path_19301_infos.json\", \"r\") as infile:\n",
    "    infos = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(infos[\"path_cells\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(np.array(infos[\"edgecosts\"]),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.array(output_paths[-1][1]), axis=0) # might be slightly different because of 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to output\n",
    "print(np.sum(np.array(path_costs),axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- work on full instance only, and only edit pos2node\n",
    "- start: full instance, only consider every fith node\n",
    "- entweder mit downsampling, oder mit randomly deleting edges\n",
    "- probability should depend on distance from path, and on cost\n",
    "- randomly delete half of the edges, find new path --> add to best path\n",
    "\n",
    "\n",
    "- reset graph methode?\n",
    "- vary hard constraints?\n",
    "\n",
    "Ideen:\n",
    "- take min instead of mean --> searching for optimal path with minimum values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance[instance==0.0001] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 4\n",
    "corridor = np.ones(instance_corr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance.shape, instance_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(img, scale_factor):\n",
    "    x_len_new = img.shape[0] // scale_factor\n",
    "    y_len_new = img.shape[1] // scale_factor\n",
    "    new_img = np.zeros((x_len_new, y_len_new))\n",
    "    print(y_len_new)\n",
    "    for i in range(x_len_new):\n",
    "        for j in range(y_len_new):\n",
    "            patch = img[i * scale_factor:(i + 1) *\n",
    "                        scale_factor, j *\n",
    "                        scale_factor:(j + 1) * scale_factor]\n",
    "            new_img[i, j] = np.mean(patch)\n",
    "    return new_img\n",
    "\n",
    "instance = np.array([reduce(inst, 4) for inst in instance])\n",
    "instance_corr = reduce(instance_corr, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corridor = np.ones(instance_corr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_inds = start_inds//4\n",
    "dest_inds = dest_inds//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import watershed\n",
    "from skimage import data, util, filters, color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.set_cost_rest(4, corridor, start_inds, dest_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(graph.cost_rest[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_orig = graph.pos2node[np.mean(graph.cost_rest,axis=0) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y = np.where(graph.cost_rest[2]>0)\n",
    "out = np.zeros(instance_corr.shape)\n",
    "for (i,j) in zip(x,y):\n",
    "    if graph.pos2node[i,j]==-1:\n",
    "        print(i,j)\n",
    "        out[i,j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(graph.cost_rest[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize graph\n",
    "graph = WeightedGraph(\n",
    "        instance, instance_corr, graphtool=1, verbose=1\n",
    "    )\n",
    "graph.set_edge_costs(LAYER_CLASSES, CLASS_WEIGHT)\n",
    "graph.set_shift(PYLON_DIST_MIN, PYLON_DIST_MAX, vec, MAX_ANGLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [(2,100), (1,0)] # scale down by factor of 4, refine with distance 100, \n",
    "# then scale down by factor of 2 in this area, refine in distance of 50\n",
    "# pipeline = [(2,70), (1,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "\n",
    "corridor = np.ones(instance_corr.shape)*0.5 # CHANGED # beginning: everything is included\n",
    "output_paths = []\n",
    "\n",
    "plot_surfaces = []\n",
    "\n",
    "for (factor, dist) in pipeline:\n",
    "    tic_down = time.time()\n",
    "    # graph.set_cost_rest(factor, corridor, start_inds, dest_inds)\n",
    "    print(\"time downsampling:\", round(time.time()-tic_down,3))\n",
    "    # plt.imshow(graph.pos2node)\n",
    "    # plt.show()\n",
    "    # plt.imshow(graph.cost_rest[2])\n",
    "    # plt.show()\n",
    "    # plot_surfaces.append(np.mean(graph.cost_rest, axis=0))\n",
    "    # print(\"set cost rest\")\n",
    "    graph.add_edges(corridor)\n",
    "    print(\"now number of edges:\", len(list(graph.graph.edges())), \"vertices:\", len(list(graph.graph.vertices())))\n",
    "    # weighted sum of all costs\n",
    "    graph.sum_costs()\n",
    "    source_v, target_v = graph.add_start_and_dest(start_inds, dest_inds)\n",
    "    print(\"start and end:\", source_v, target_v)\n",
    "    # get actual best path\n",
    "    path, path_costs = graph.get_shortest_path(source_v, target_v)\n",
    "    output_paths.append((path, path_costs)) # save for inspection\n",
    "    # get several paths --> here: pareto paths\n",
    "    paths = [path] # graph.get_pareto(np.arange(0, 1.1, 0.1), source_v, target_v, compare=[2, 3])\n",
    "    if dist > 0:\n",
    "        # do specified numer of dilations\n",
    "        dist_surface = get_distance_surface(graph.pos2node.shape, paths, mode=\"dilation\", n_dilate=dist)\n",
    "        # plotting\n",
    "        plt.imshow(dist_surface>0)\n",
    "        plt.show()\n",
    "        # remove the edges of vertices in the corridor (to overwrite)\n",
    "        graph.remove_vertices((dist_surface>0).astype(int)) # PYLON_DIST_MAX\n",
    "        # set new corridor\n",
    "        # corridor = (dist_surface >0).astype(int)\n",
    "        corridor = normalize(dist_surface)\n",
    "\n",
    "print(\"DONE\", time.time() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = lambda x: 1/(1+np.exp(3*(-x+5)))\n",
    "plt.plot([sm(x) for x in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path, path_costs = graph.get_shortest_path(source_v, target_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = graph.get_pareto(np.arange(0, 1.1, 0.1), source_v, target_v, compare=[2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_surface = get_distance_surface(graph.pos2node.shape, paths, mode=\"dilation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dist_surface>30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only change cost_rest, not pos2node\n",
    "# use max instead of mean --> replacing the edge is always improving it\n",
    "# use find_edge to determine edges with high cost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.remove_vertices((dist_surface>30).astype(int))\n",
    "graph.update_cost_rest((dist_surface>15).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(20).reshape(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in graph.graph.vertex(target_v).in_neighbors():\n",
    "    print(v)\n",
    "    for u in v.in_neighbors():\n",
    "        print(u)\n",
    "        print([k for k in u.in_neighbors()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([v for v in graph.graph.vertex(6448512).out_neighbors()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(graph.graph.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_tuple_2_pos_tuples(n1, n2, graph):\n",
    "    (x,y) = (n1//graph.n_neighbors, n1 % graph.n_neighbors)\n",
    "    tup1 = ((x // graph.y_len, x % graph.y_len), (y // graph.y_len, y % graph.y_len))\n",
    "    (x,y) = (n2//graph.n_neighbors, n2 % graph.n_neighbors)\n",
    "    tup2 = ((x // graph.y_len, x % graph.y_len), (y // graph.y_len, y % graph.y_len))\n",
    "    return tup1, tup2\n",
    "edge_tuple_2_pos_tuples(6716500,1062881, graph)\n",
    "# graph.angle_tuples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.x_len, graph.y_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize graph\n",
    "graph = LineGraph(\n",
    "        instance, instance_corr, graphtool=1, verbose=1\n",
    "    )\n",
    "graph.set_edge_costs(LAYER_CLASSES, CLASS_WEIGHT)\n",
    "graph.set_shift(PYLON_DIST_MIN, PYLON_DIST_MAX, vec, MAX_ANGLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(graph.corridor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.set_cost_rest(0.8, instance_corr, start_inds, dest_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.sum_costs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_v, target_v = graph.add_start_and_dest(start_inds, dest_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start and end:\", source_v, target_v)\n",
    "path, path_costs = graph.get_shortest_path(source_v, target_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from graph_tool.all import Graph, shortest_path, load_graph\n",
    "\n",
    "from power_planner.utils.utils import angle, get_lg_donut, normalize\n",
    "from power_planner.utils.utils_constraints import ConstraintUtils\n",
    "\n",
    "from general_graph import GeneralGraph\n",
    "\n",
    "\n",
    "class LineGraph(GeneralGraph):\n",
    "    \"\"\"\n",
    "    Build a line graph for incorporating angle costs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cost_instance,\n",
    "        hard_constraints,\n",
    "        directed=True,\n",
    "        graphtool=1,\n",
    "        verbose=1\n",
    "    ):\n",
    "        tic = time.time()\n",
    "        # assert cost_instance.shape == hard_constraints.shape\n",
    "        self.cost_instance = cost_instance\n",
    "        self.hard_constraints = hard_constraints\n",
    "\n",
    "        # initilize graph\n",
    "        GeneralGraph.__init__(\n",
    "            self, directed=directed, graphtool=graphtool, verbose=verbose\n",
    "        )\n",
    "        \n",
    "        self.x_len, self.y_len = hard_constraints.shape\n",
    "\n",
    "        self.time_logs = {}\n",
    "        self.time_logs[\"init_graph\"] = round(time.time() - tic, 3)\n",
    "        \n",
    "    def _edge2node(self, v1_arr, shift):\n",
    "        \"\"\"\n",
    "        binary arrays of same shape as pos2v1\n",
    "        \"\"\"\n",
    "        neighbor_ind = self.shift_dict[tuple(shift)]\n",
    "        return self.pos2node[v1_arr] * self.n_neighbors + neighbor_ind\n",
    "        # return self.pos2node[v1_arr] * self.n_entries + self.pos2node[v2_arr]\n",
    "        \n",
    "    def set_cost_rest(self, factor, corridor, start_inds, dest_inds):\n",
    "        \"\"\"\n",
    "        factor: in this case ratio of edges to remove\n",
    "        \"\"\"\n",
    "        assert factor < 1, \"for RandomGraph factor must be smaller 1\"\n",
    "        self.factor = factor\n",
    "        # set pos2node\n",
    "        self.pos2node = np.arange(1, self.x_len * self.y_len + 1).reshape(\n",
    "            (self.x_len, self.y_len)\n",
    "        )\n",
    "        self.n_entries = self.x_len * self.y_len\n",
    "        self.n_neighbors = len(self.shifts)\n",
    "        self.shift_dict = {tuple(s):i for i,s in enumerate(self.shifts)}\n",
    "        \n",
    "        # set corridor: exp of distances\n",
    "        corridor = corridor * (self.hard_constraints > 0).astype(int)\n",
    "        if self.factor == 0:\n",
    "            # make sure all points in corridor are taken\n",
    "            self.corridor = (corridor > 0).astype(int) * 1.1\n",
    "        else:\n",
    "            corridor = normalize(corridor)\n",
    "            cutoff = np.quantile(corridor, factor)\n",
    "            if cutoff == 1:\n",
    "                self.corridor = corridor - factor\n",
    "            else:\n",
    "                self.corridor = corridor + 0.5 - cutoff\n",
    "                # set cutoff # normalize(np.exp(\n",
    "                # self.cutoff = max([0.5, cutoff])  # must be at least 0.5!\n",
    "                # - 0.5 + self.cutoff\n",
    "            print(\n",
    "                \"max min corridor\", np.max(self.corridor),\n",
    "                np.min(self.corridor)\n",
    "            )\n",
    "            print(\"cutoff corridor vals\", cutoff)\n",
    "        \n",
    "    def set_cost_rest_old(self, factor, dist_surface, start_inds, dest_inds):\n",
    "        # original pos2node: all filled except for hard constraints\n",
    "        self.pos2node = np.arange(1, self.x_len * self.y_len + 1).reshape(\n",
    "            (self.x_len, self.y_len)\n",
    "        )\n",
    "        self.n_entries = self.x_len * self.y_len\n",
    "        self.n_neighbors = len(self.shifts)\n",
    "        self.shift_dict = {tuple(s):i for i,s in enumerate(self.shifts)}\n",
    "        \n",
    "        corridor = (dist_surface > 0).astype(int)\n",
    "\n",
    "        self.factor = factor\n",
    "        self.cost_rest = self.cost_instance * (self.hard_constraints >\n",
    "                                               0).astype(int) * corridor\n",
    "        # DOWNSAMPLE\n",
    "        tic = time.time()\n",
    "        if factor > 1:\n",
    "            self.cost_rest = CostUtils.downsample(\n",
    "                self.cost_rest, factor, func=\"min\"\n",
    "            )\n",
    "        self.time_logs[\"downsample\"] = round(time.time() - tic, 3)\n",
    "\n",
    "        # repeat because edge artifacts\n",
    "        self.cost_rest = self.cost_rest * (self.hard_constraints >\n",
    "                                           0).astype(int) * corridor\n",
    "\n",
    "        # add start and end TODO ugly\n",
    "        self.cost_rest[:, dest_inds[0],\n",
    "                       dest_inds[1]] = self.cost_instance[:, dest_inds[0],\n",
    "                                                          dest_inds[1]]\n",
    "        self.cost_rest[:, start_inds[0],\n",
    "                       start_inds[1]] = self.cost_instance[:, start_inds[0],\n",
    "                                                           start_inds[1]]\n",
    "\n",
    "\n",
    "    def set_shift(self, lower, upper, vec, max_angle):\n",
    "        \"\"\"\n",
    "        Get donut tuples (for vertices) and angle tuples (for edges)\n",
    "        \"\"\"\n",
    "        GeneralGraph.set_shift(self, lower, upper, vec, max_angle)\n",
    "        self.angle_tuples = get_lg_donut(lower, upper, vec)\n",
    "\n",
    "    def set_edge_costs(self, classes, weights=None):\n",
    "        \"\"\"\n",
    "        Initialize edge properties as in super, but add angle costs\n",
    "        \"\"\"\n",
    "        # classes = [\"angle\", \"env\", \"urban\"]  # data.layer_classes + [\"angle\"]\n",
    "        classes = [\"angle\"] + classes\n",
    "        if len(weights) < len(classes):\n",
    "            print(\"insert weight 1 for angle costs\")\n",
    "            weights = [1] + list(weights)  # append angle weight\n",
    "        print(\"edge costs classes:\", classes)\n",
    "        GeneralGraph.set_edge_costs(self, classes, weights=weights)\n",
    "\n",
    "    def add_nodes(self):\n",
    "        GeneralGraph.add_nodes(self, self.n_entries * self.n_neighbors)\n",
    "        \n",
    "    def _compute_edges(self, shift):\n",
    "        \"\"\"\n",
    "        Get all valid edges given a certain shift\n",
    "        :param mask: binary 2d array marking forbidden areas\n",
    "        \"\"\"\n",
    "        # get all angles that are possible\n",
    "        in_node = ConstraintUtils.shift_surface(\n",
    "            self.hard_constraints,\n",
    "            np.asarray(shift[0]) * (-1)\n",
    "        )\n",
    "        out_node = ConstraintUtils.shift_surface(\n",
    "            self.hard_constraints,\n",
    "            np.asarray(shift[1]) * (-1)\n",
    "        )\n",
    "        stacked = np.asarray([self.hard_constraints, in_node, out_node])\n",
    "        all_angles = np.all(stacked, axis=0)\n",
    "\n",
    "        # shift again, andersrum\n",
    "        in_node = ConstraintUtils.shift_surface(\n",
    "            all_angles,\n",
    "            np.asarray(shift[0])\n",
    "        )\n",
    "        out_node = ConstraintUtils.shift_surface(\n",
    "            all_angles,\n",
    "            np.asarray(shift[1])\n",
    "        )\n",
    "\n",
    "        e1 = self._edge2node(in_node, np.array(shift[0])*(-1)) # in_node, all_angles,\n",
    "        e2 = self._edge2node(all_angles, shift[1])\n",
    "\n",
    "        # print(e1.shape, e2.shape)\n",
    "        # print(e1[:20], e2[:20])\n",
    "\n",
    "        # cost at edge in lg is cost of node tower inbetween\n",
    "        # node_cost = [self.cost_instance[all_angles]]\n",
    "        \n",
    "        # new version TODO\n",
    "        node_cost_list = [\n",
    "            cost_surface[all_angles] for cost_surface in self.cost_rest\n",
    "        ]\n",
    "        node_cost_arr = np.array(node_cost_list)\n",
    "        \n",
    "        pos = (np.sum(node_cost_arr, axis=0) > 0).astype(bool)\n",
    "        \n",
    "        return e1[pos], e2[pos], node_cost_arr[:, pos] # e1, e2, node_cost_arr# \n",
    "\n",
    "    def add_edges(self):\n",
    "        \"\"\"\n",
    "        Add edges to line graph: Iterate over angle tuples, retrieve nodes,\n",
    "        add if angle is possible with corresponding angle cost\n",
    "        \"\"\"\n",
    "        tic_function = time.time()\n",
    "\n",
    "        times_edge_list = []\n",
    "        times_add_edges = []\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                \"Start adding edges...\", len(self.angle_tuples), \"iterations\"\n",
    "            )\n",
    "        # for every angle in the new angle tuples\n",
    "        for shift in self.angle_tuples:\n",
    "            tic_edges = time.time()\n",
    "            # get cost for angle\n",
    "            \n",
    "            prob_arr = np.random.rand(*self.corridor.shape)\n",
    "            prob_arr = (self.corridor > prob_arr).astype(int)\n",
    "            self.cost_rest = self.cost_instance * prob_arr\n",
    "        \n",
    "            e1, e2, node_cost_arr = self._compute_edges(shift)\n",
    "            \n",
    "            angle_weight = [shift[2] for _ in range(len(e1))]\n",
    "            inds_arr = np.asarray([e1, e2, angle_weight])\n",
    "            inds_weights = np.concatenate((inds_arr, node_cost_arr), axis=0)\n",
    "            edges_lg = np.swapaxes(inds_weights, 1, 0)\n",
    "            \n",
    "            # save time\n",
    "            times_edge_list.append(round(time.time() - tic_edges, 3))\n",
    "            # add to graph\n",
    "            tic_graph = time.time()\n",
    "            if np.any(edges_lg[:2].flatten() < 0):\n",
    "                print(np.where(out[:2] <0))\n",
    "                raise RuntimeError\n",
    "            self.graph.add_edge_list(edges_lg, eprops=self.cost_props)\n",
    "            times_add_edges.append(round(time.time() - tic_graph, 3))\n",
    "\n",
    "        # time logs\n",
    "        self._update_time_logs(times_add_edges, times_edge_list, tic_function)\n",
    "\n",
    "    def add_start_and_dest(self, source, dest):\n",
    "        \"\"\"\n",
    "        start and dest are no vertices in line graph, so need to add them\n",
    "        seperately\n",
    "        --> get all outgoing edges from source\n",
    "        --> create new start vertex, connect to all outgoing edges\n",
    "        :returns: newly created source and dest vertices\n",
    "        \"\"\"\n",
    "        tic = time.time()\n",
    "        possible_start_edges = [self.pos2node[source[0], source[1]] * self.n_neighbors + self.shift_dict[tuple(shift)] for shift in self.shifts]\n",
    "            \n",
    "        possible_dest_edges = []\n",
    "        for shift in self.shifts:\n",
    "            shifted_dest = np.asarray(dest) - np.asarray(shift)\n",
    "            possible_dest_edges.append(self.pos2node[shifted_dest[0], shifted_dest[1]] * self.n_neighbors + self.shift_dict[tuple(shift)])\n",
    "        print(possible_dest_edges)\n",
    "        \n",
    "        start_v = self.graph.add_vertex()\n",
    "        dest_v = self.graph.add_vertex()\n",
    "        start_ind = self.graph.vertex_index[start_v]\n",
    "        dest_ind = self.graph.vertex_index[dest_v]\n",
    "\n",
    "        mean_costs = np.mean(self.cost_instance, axis=(1, 2)).tolist()\n",
    "        mean_costs.insert(0, 0)  # insert zero angle cost\n",
    "        print(\"mean costs:\", mean_costs)  # TODO: leave this?\n",
    "\n",
    "        start_edges = [\n",
    "            [start_ind, u] + mean_costs for u in possible_start_edges\n",
    "        ]\n",
    "        dest_edges = [[u, dest_ind] + mean_costs for u in possible_dest_edges]\n",
    "        self.graph.add_edge_list(start_edges, eprops=self.cost_props)\n",
    "        self.graph.add_edge_list(dest_edges, eprops=self.cost_props)\n",
    "\n",
    "        self.time_logs[\"add_start_end\"] = round(time.time() - tic, 3)\n",
    "\n",
    "        return [start_v, dest_v]\n",
    "\n",
    "    def get_shortest_path(self, source, dest):\n",
    "        \"\"\"\n",
    "        Compute shortest path and convert from line graph representation to \n",
    "        coordinates\n",
    "        \"\"\"\n",
    "        vertices_path = GeneralGraph.get_shortest_path(self, source, dest)\n",
    "        out_path = []\n",
    "        for v in vertices_path[1:-1]:\n",
    "            (start_node, shift_ind) = (int(v)//graph.n_neighbors, int(v) % graph.n_neighbors)\n",
    "            start_pos = [start_node // graph.y_len, start_node % graph.y_len]\n",
    "            out_path.append(start_pos)\n",
    "        \n",
    "        # append last on\n",
    "        out_path.append(list(np.array(start_pos) + self.shifts[shift_ind]))\n",
    "        \n",
    "        out_costs = []\n",
    "        for (i, j) in out_path:\n",
    "            out_costs.append(self.cost_instance[:, i, j].tolist())\n",
    "            \n",
    "        return out_path, out_costs\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralGraph():\n",
    "\n",
    "    def __init__(self, graphtool=1, directed=True, verbose=1):\n",
    "        if graphtool:\n",
    "            self.graph = Graph(directed=directed)\n",
    "            self.weight = self.graph.new_edge_property(\"float\")\n",
    "        else:\n",
    "            if directed:\n",
    "                print(\"directed graph\")\n",
    "                self.graph = nx.DiGraph()\n",
    "            else:\n",
    "                self.graph = nx.Graph()\n",
    "        self.time_logs = {}\n",
    "        self.verbose = verbose\n",
    "        self.graphtool = graphtool\n",
    "\n",
    "    def set_edge_costs(self, classes, weights=None):\n",
    "        if weights is None:\n",
    "            weights = [1 for i in range(len(classes))]\n",
    "        weights = np.array(weights)\n",
    "        # set different costs:\n",
    "        self.cost_classes = classes\n",
    "        self.cost_props = [\n",
    "            self.graph.new_edge_property(\"float\") for _ in range(len(classes))\n",
    "        ]\n",
    "        self.cost_weights = weights / np.sum(weights)\n",
    "        print(self.cost_classes, self.cost_weights)\n",
    "\n",
    "    def set_shift(self, lower, upper, vec, max_angle):\n",
    "        self.shifts = get_half_donut(lower, upper, vec, angle_max=max_angle)\n",
    "\n",
    "    def add_nodes(self, nodes):\n",
    "        \"\"\"\n",
    "        param nodes: list of node names if networkx, integer if graphtool\n",
    "        \"\"\"\n",
    "        tic = time.time()\n",
    "        # add nodes to graph\n",
    "        if self.graphtool:\n",
    "            _ = self.graph.add_vertex(nodes)\n",
    "        else:\n",
    "            self.graph.add_nodes_from(np.arange(nodes))\n",
    "        # verbose\n",
    "        if self.verbose:\n",
    "            print(\"Added nodes:\", nodes, \"in time:\", time.time() - tic)\n",
    "        self.time_logs[\"add_nodes\"] = round(time.time() - tic, 3)\n",
    "\n",
    "    def sum_costs(self):\n",
    "        # add sum of all costs\n",
    "        tic = time.time()\n",
    "        summed_costs_arr = np.zeros(self.cost_props[0].get_array().shape)\n",
    "        for i in range(len(self.cost_props)):\n",
    "            prop = self.cost_props[i].get_array()\n",
    "            summed_costs_arr += prop * self.cost_weights[i]\n",
    "        self.weight.a = summed_costs_arr\n",
    "\n",
    "        self.time_logs[\"sum_of_costs\"] = round(time.time() - tic, 3)\n",
    "\n",
    "    def get_pareto(self, vary, source, dest, out_path=None, compare=[0, 1]):\n",
    "        \"\"\"\n",
    "        compute shortest paths with varied weights\n",
    "        \"\"\"\n",
    "        pareto = list()\n",
    "        paths = list()\n",
    "        cost0 = self.cost_props[compare[0]].get_array()\n",
    "        cost1 = self.cost_props[compare[1]].get_array()\n",
    "        class0 = self.cost_classes[compare[0]]\n",
    "        class1 = self.cost_classes[compare[1]]\n",
    "        # test_edge = find_edge(self.graph, self.graph.edge_index, 44)[0]\n",
    "        for w in vary:\n",
    "            self.weight.a = cost0 * w + cost1 * (1 - w)\n",
    "            # print(\"test weight\", self.weight[test_edge])\n",
    "            path, path_costs = self.get_shortest_path(source, dest)\n",
    "            # print(\n",
    "            #     class0, \"weight:\", w, class1, \"weight:\", 1 - w, \"costs:\",\n",
    "            #     np.mean(path_costs, axis=0)\n",
    "            # )\n",
    "            pareto.append(np.sum(path_costs, axis=0))\n",
    "            paths.append(path)\n",
    "        # PLOTTING:\n",
    "        # pareto = np.asarray(pareto)\n",
    "        # pareto0 = pareto[:, compare[0]]\n",
    "        # pareto1 = pareto[:, compare[1]]\n",
    "        # plot_pareto(\n",
    "        #     pareto0, pareto1, paths, vary, [class0, class1], out_path=out_path\n",
    "        # )\n",
    "        # plot_pareto_paths(paths, [class0, class1], out_path=out_path)\n",
    "        return paths\n",
    "\n",
    "    def get_shortest_path(self, source, target):\n",
    "        \"\"\"\n",
    "        Compute shortest path from source vertex to target vertex\n",
    "        \"\"\"\n",
    "        tic = (time.time())\n",
    "        # #if source and target are given as indices:\n",
    "        if self.graphtool:\n",
    "            vertices_path, _ = shortest_path(\n",
    "                self.graph,\n",
    "                source,\n",
    "                target,\n",
    "                weights=self.weight,\n",
    "                negative_weights=True\n",
    "            )\n",
    "        else:\n",
    "            vertices_path = nx.dijkstra_path(self.graph, source, target)\n",
    "\n",
    "        self.time_logs[\"shortest_path\"] = round(time.time() - tic, 3)\n",
    "        return vertices_path\n",
    "\n",
    "    def save_graph(self, OUT_PATH):\n",
    "        if self.graphtool:\n",
    "            for i, cost_class in enumerate(self.cost_classes):\n",
    "                self.graph.edge_properties[cost_class] = self.cost_props[i]\n",
    "            self.graph.edge_properties[\"weight\"] = self.weight\n",
    "            self.graph.save(OUT_PATH + \".xml.gz\")\n",
    "        else:\n",
    "            nx.write_weighted_edgelist(\n",
    "                self.graph, OUT_PATH + '.weighted.edgelist'\n",
    "            )\n",
    "\n",
    "    def load_graph(self, IN_PATH):\n",
    "        if self.graphtool:\n",
    "            self.g_prev = load_graph(IN_PATH + \".xml.gz\")\n",
    "            self.weight_prev = self.g_prev.ep.weight\n",
    "            # weight = G2.ep.weight[G2.edge(66, 69)]\n",
    "        else:\n",
    "            self.g_prev = nx.read_edgelist(\n",
    "                IN_PATH + '.weighted.edgelist',\n",
    "                nodetype=int,\n",
    "                data=(('weight', float), )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_path_costs(graph.cost_rest, (np.array(infos[\"path_cells\"])/2).astype(int), infos[\"edgecosts\"], graph.cost_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear infrastructure, optimal path planning, network OPTLINE, optimal power transport by LOPT LION \n",
    "optimal power transport infrastructure by LIOPT graph modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.array(output_paths[-1][1]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pipeline_paths(plot_surfaces, output_paths, buffer=1, out_path=None):\n",
    "    \"\"\"\n",
    "    subplots of different steps in the pipeline\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for i, (p, p_cost) in enumerate(output_paths):\n",
    "        plt.subplot(1, len(output_paths), i + 1)\n",
    "\n",
    "        # expand to greyscale\n",
    "        expanded = np.expand_dims(plot_surfaces[i], axis=2)\n",
    "        expanded = np.tile(\n",
    "            expanded, (1, 1, 3)\n",
    "        )  # overwrite instance by tiled one\n",
    "        # colour nodes in path in red\n",
    "        for (x, y) in p:\n",
    "            expanded[x - buffer:x + buffer + 1, y - buffer:y + buffer +\n",
    "                     1] = [0.9, 0.2, 0.2]  # colour red\n",
    "        plt.imshow(np.swapaxes(expanded, 1, 0), origin=\"lower\")\n",
    "        print(\"costs\", np.sum(np.array(p_cost), axis=0))\n",
    "    plt.tight_layout()\n",
    "    if out_path is not None:\n",
    "        plt.savefig(out_path, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(np.array(output_paths[-1][1]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_path(graph.cost_rest[2], path, buffer=0) # graph.cost_rest[2], output_paths[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_pipeline_paths(plot_surfaces, output_paths, buffer=1, out_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = np.array(infos[\"path_cells\"])\n",
    "costs_new = []\n",
    "for i in range(len(gt)-1):\n",
    "    (h,j) = gt[i]\n",
    "    (k,l) = gt[i+1]\n",
    "    v1 = graph.pos2node[int(h//2), j//2]\n",
    "    v2 = graph.pos2node[int(k//2), l//2]\n",
    "    found=False\n",
    "    for w in graph.graph.vertex(v1).out_neighbors():\n",
    "        if w==v2:\n",
    "            found=True\n",
    "    # print(found)\n",
    "    e = graph.graph.edge(graph.graph.vertex(v1), graph.graph.vertex(v2))\n",
    "    c = [cost[e] for cost in graph.cost_props]\n",
    "    costs_new.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.array(costs_new), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST THAT EDGES ARE NOT OVERWRITTEN - MULTIGRAPH\n",
    "g = Graph()\n",
    "w = g.new_edge_property(\"float\")\n",
    "edges = []\n",
    "for i in range(20):\n",
    "    edges.append([i,i+1,i])\n",
    "g.add_edge_list(edges, eprops=[w])\n",
    "# e = find_edge(g, g.edge_index, 13)\n",
    "\n",
    "new_edges = []\n",
    "for i in range(15,20):\n",
    "    new_edges.append([i,i+1,i-5])\n",
    "g.add_edge_list(new_edges, eprops=[w])\n",
    "\n",
    "e = g.add_edge(g.vertex(13), g.vertex(14))\n",
    "w[e] = 10\n",
    "\n",
    "for e in g.edges():\n",
    "    print(e)\n",
    "    print(w[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from power_planner.utils.utils import normalize\n",
    "dist_surface = normalize(dist_surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists_orig = get_distance_surface(dist_surface.shape, [path], n_dilate=200)\n",
    "# get_distance_surface(graph.pos2node.shape, paths, mode=\"dilation\", n_dilate=dist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = normalize(np.exp(normalize(dists_orig)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_rem = 0.99\n",
    "cutoff = np.quantile(dists, ratio_rem)\n",
    "print(cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.rand(*dist_surface.shape)-0.5+cutoff # (arr-cutoff+0.5)\n",
    "print(np.mean(arr))\n",
    "prob_arr = (dists > arr).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(prob_arr)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"prob kept\", np.sum((prob_arr>0).astype(int)) / (arr.shape[0]*arr.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = np.quantile(dist_surface/100, 0.25)\n",
    "prob_arr = (dist_surface/100 > (arr-cutoff+0.5)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of edges we want in the end --> divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set self.cost_rest different for every shift --> multiply self.cost_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cost_rest(self, corridor):\n",
    "        # UNUSED method\n",
    "        inverted_corridor = np.absolute(1-corridor).astype(bool)\n",
    "        self.pos2node[inverted_corridor] = -1\n",
    "        \n",
    "    def set_pos2node(self, img, factor):\n",
    "        # UNUSED METHOD\n",
    "        x_len_new = img.shape[1] // factor\n",
    "        y_len_new = img.shape[2] // factor\n",
    "        pos2node = np.zeros((img.shape[1], img.shape[2]))\n",
    "        new_img = np.zeros(img.shape)\n",
    "        pos2node += -1\n",
    "        lab = 0\n",
    "        for i in range(x_len_new):\n",
    "            for j in range(y_len_new):\n",
    "                patch = img[:, i * factor:(i + 1) * factor, j * factor:(j + 1) * factor]\n",
    "                if np.any(patch):\n",
    "                    pos2node[i * factor:(i + 1) * factor, j * factor:(j + 1) * factor] = lab\n",
    "                    lab += 1\n",
    "                # x_cost = int(mean([i * factor, (i + 1) * factor])\n",
    "                    for k in range(len(new_img)):\n",
    "                        part = patch[k]\n",
    "                        if np.any(part):\n",
    "                            new_img[k, i*factor, j*factor] = np.mean(part[part>0])\n",
    "        return pos2node, new_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corridor prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_path = \"../../data/instance_belgium/corridor/Corridor.tif\"\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_corrs(corrs, out_path=None):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    for i,corr in enumerate(corrs):\n",
    "        plt.subplot(1,len(corrs),(i+1))\n",
    "        plt.imshow(corr)\n",
    "    if out_path is not None:\n",
    "        plt.savefig(out_path+\"corridor_quantiles.png\")\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "def corrs_from_file(corr_path):\n",
    "    with rasterio.open(corr_path, 'r') as ds:\n",
    "        cost_img = ds.read()[0]\n",
    "    print(\"read in cost array\", cost_img.shape)\n",
    "    actual_vals = cost_img[cost_img!=9999]\n",
    "    \n",
    "    corrs = []\n",
    "    cut_val_prev = 0\n",
    "    log_vals = np.logspace(np.log(0.03), np.log(1),4, base=1.5)\n",
    "    for i in range(4):\n",
    "        cut_val = np.quantile(actual_vals, log_vals[i]) # (i+1)*0.24)\n",
    "        copied = cost_img.copy()\n",
    "        copied[copied<cut_val_prev] = 9999\n",
    "        copied[copied>cut_val] = 9999\n",
    "        corrs.append((copied!=9999).astype(int))\n",
    "        cut_val_prev = cut_val\n",
    "    return corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = corrs_from_file(corr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_corrs(corrs, out_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_vals = cost_img[cost_img!=9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_middle_line(start_inds, dest_inds, instance_corr, num_points = 2):\n",
    "    vec = (dest_inds - start_inds)/2\n",
    "    middle_point = start_inds + vec\n",
    "    ortho_vec = [-vec[1], vec[0]]\n",
    "    ortho_vec = ortho_vec/np.linalg.norm(ortho_vec)\n",
    "\n",
    "    inds_x, inds_y = np.where(instance_corr)\n",
    "    xs, xe = (inds_x[0], inds_x[-1])\n",
    "    ys, ye = (inds_y[0], inds_y[-1])\n",
    "    x,y = tuple(middle_point)\n",
    "    v1, v2 = tuple(ortho_vec)\n",
    "    \n",
    "    dists_each = min(np.absolute([(x-xs)/v1, (xe-x)/v1, (y-ys)/v2, (ye-y)/v2])) / (num_points+1)\n",
    "    \n",
    "    points = [middle_point.astype(int)] # start_inds, dest_inds,\n",
    "    for i in range(num_points):\n",
    "        points.append((middle_point + ortho_vec*dists_each*(i+1)).astype(int))\n",
    "        points.append((middle_point - ortho_vec*dists_each*(i+1)).astype(int))\n",
    "    return points\n",
    "\n",
    "def generate_corridors_middle_line(instance_corr, start_inds, dest_inds, num_corrs = 5, n_dilate=100):\n",
    "    num_middle_points = num_corrs//2\n",
    "    points = get_middle_line(start_inds, dest_inds, instance_corr, num_points = num_middle_points)\n",
    "    all_corridors = []\n",
    "    for p in points:\n",
    "        path = [[start_inds.tolist(), p.tolist(), dest_inds.tolist()]]\n",
    "        all_corridors.append(get_distance_surface(instance_corr.shape, path, n_dilate=n_dilate))\n",
    "    return all_corridors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_middle_line(all_points, instance_corr, buffer=2, out_path=None):\n",
    "    example = instance_corr.copy()\n",
    "    for p in all_points:\n",
    "        (i,j) = tuple(p)\n",
    "        example[i-buffer:i+buffer,j-buffer:j+buffer] = 2\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(example)\n",
    "    if out_path is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(out_path+\"_corr_lines.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = get_middle_line(start_inds, dest_inds, instance_corr, num_points = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_middle_line(all_points, instance_corr, buffer=2, out_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0,y0 = tuple(start_inds)\n",
    "x2,y2 = tuple(dest_inds)\n",
    "\n",
    "all_points = []\n",
    "for (x1,y1) in points:\n",
    "    l1 = bresenham_line(x0,y0,x1,y1)\n",
    "    l2 = bresenham_line(x1,y1,x2,y2)\n",
    "    all_points.extend(l1)\n",
    "    all_points.extend(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = generate_corridors(instance_corr, start_inds, dest_inds, num_corrs = 5, n_dilate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in all_corrs:\n",
    "    plt.imshow(c)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: move reduce to utils? copy get_reduced function to corridor utils\n",
    "def reduce(img, scale_factor):\n",
    "    x_len_new = img.shape[0] // scale_factor\n",
    "    y_len_new = img.shape[1] // scale_factor\n",
    "    new_img = np.zeros((x_len_new, y_len_new))\n",
    "    for i in range(x_len_new):\n",
    "        for j in range(y_len_new):\n",
    "            patch = img[i * scale_factor:(i + 1) *\n",
    "                        scale_factor, j *\n",
    "                        scale_factor:(j + 1) * scale_factor]\n",
    "            new_img[i, j] = np.mean(patch)\n",
    "    return new_img\n",
    "\n",
    "def get_reduced_patches(instance, start_inds, dest_inds, factor, balance=[1,1], quantile=0.1):\n",
    "    summed = np.sum(instance, axis=0)\n",
    "    red= reduce(summed, factor)\n",
    "    x_len,y_len = red.shape\n",
    "    path_start_end = [[(start_inds/factor).astype(int).tolist(), (dest_inds/factor).astype(int).tolist()]]\n",
    "    dist_corr = 1-normalize(get_distance_surface(red.shape, path_start_end, n_dilate=min([x_len,y_len])))\n",
    "    surface_comb = balance[0] * dist_corr + balance[1] * red\n",
    "    \n",
    "    quantile_surface = np.quantile(surface_comb, quantile)\n",
    "    patches = surface_comb < quantile_surface\n",
    "    plt.imshow(patches.astype(int))\n",
    "    plt.show()\n",
    "    \n",
    "    inds_x, inds_y = np.where(patches)\n",
    "    return np.array([inds_x, inds_y]) # *factor\n",
    "\n",
    "def generate_corridors_sample_path(instance, start_inds, dest_inds, factor=80, balance=[1,3], quantile=0.1, n_sample=4, n_onpath=5, n_dilate=100):\n",
    "    out_inds = get_reduced_patches(instance, start_inds, dest_inds, factor, balance=[1,3], quantile=0.1)\n",
    "    # compute distances from start point\n",
    "    minus_start = [np.linalg.norm(out_inds[:,i] - start_inds/factor) for i in range(out_inds.shape[1])]\n",
    "    sorted_patches = np.argsort(minus_start)\n",
    "    all_corridors = list()\n",
    "    for _ in range(n_sample):\n",
    "        drawn_points = np.random.choice(np.arange(out_inds.shape[1]), n_onpath, replace=False)\n",
    "        drawn_path = out_inds[:, sorted_patches[np.sort(drawn_points)]] * factor\n",
    "        path = [[start_inds.tolist()] + np.swapaxes(drawn_path, 1,0).tolist() + [dest_inds.tolist()]]\n",
    "        print(path)\n",
    "        all_corridors.append(get_distance_surface(instance.shape[1:], path, n_dilate=n_dilate))\n",
    "    return all_corridors\n",
    "\n",
    "def generate_corridors(instance, instance_corr, start_inds, dest_inds, mode=\"jannis_idea\"):\n",
    "    if mode==\"jannis_idea\":\n",
    "        corrs = generate_corridors_sample_path(instance, start_inds, dest_inds)\n",
    "    elif mode==\"from_file\":\n",
    "        corrs = corrs_from_file(corr_path)\n",
    "    elif mode==\"middle_line\":\n",
    "        corrs = generate_corridors_middle_line(instance_corr, start_inds, dest_inds)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    for c in corrs:\n",
    "        plt.imshow(c)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "150**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_corridors(instance, instance_corr, start_inds, dest_inds, mode=\"from_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corrs = sample_path(instance, start_inds, dest_inds, 80, balance=[1,3], quantile=0.1, n_sample=5, n_onpath=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_inds/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by distance from start point?\n",
    "minus_start = [np.linalg.norm(out_inds[:,i] -start_inds/FACTOR) for i in range(out_inds.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_patches = np.argsort(minus_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_HIT = 5\n",
    "drawn_path = np.random.choice(np.arange(out_inds.shape[1]), NR_HIT, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawn_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = out_inds[:, sorted_patches[np.sort(drawn_path)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(new)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prior_paths(plot_surfaces, output_paths, buffer=2, out_path=None):\n",
    "    \"\"\"\n",
    "    subplots of different steps in the pipeline\n",
    "    plot_surfaces = nr_corrs * nr_pipeline\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for corr in range(len(plot_surfaces)):\n",
    "        \n",
    "        for i, p in enumerate(output_paths[corr]):\n",
    "            plt.subplot(len(plot_surfaces), len(output_paths[corr]), (len(output_paths[corr])*corr)+i + 1)\n",
    "\n",
    "            # expand to greyscale\n",
    "            expanded = np.expand_dims(plot_surfaces[corr][i], axis=2)\n",
    "            expanded = np.tile(expanded, (1, 1, 3))\n",
    "            # colour nodes in path in red\n",
    "            for (x, y) in p:\n",
    "                expanded[x - buffer:x + buffer + 1, y - buffer:y + buffer +\n",
    "                         1] = [0.9, 0.2, 0.2]  # colour red\n",
    "            plt.imshow(expanded, origin=\"upper\")\n",
    "    plt.tight_layout()\n",
    "    if out_path is not None:\n",
    "        plt.savefig(out_path, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    plt.subplot(2,3,(i+1))\n",
    "    plt.imshow(all_corrs[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
