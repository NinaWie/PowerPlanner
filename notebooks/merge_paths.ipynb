{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# utils imports\n",
    "from power_planner.data_reader import DataReader\n",
    "from power_planner import graphs\n",
    "from power_planner.plotting import plot_path_costs, plot_pipeline_paths, plot_path, plot_k_sp\n",
    "from power_planner.utils.utils import get_distance_surface, time_test_csv\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_FILES = \"../data\"\n",
    "\n",
    "# DEFINE CONFIGURATION\n",
    "ID = \"w_ksp_5\"  # str(round(time.time() / 60))[-5:]\n",
    "\n",
    "OUT_PATH = \"outputs/path_\" + ID\n",
    "SCALE_PARAM = 5  # args.scale\n",
    "PIPELINE = [(1, 0)]  # [(0.9, 40), (0, 0)]\n",
    "\n",
    "GRAPH_TYPE = graphs.WeightedGraph\n",
    "# LineGraph, WeightedGraph, RandomWeightedGraph, RandomLineGraph, PowerBF\n",
    "# TwoPowerBF, WeightedKSP\n",
    "print(\"graph type:\", GRAPH_TYPE)\n",
    "# summarize: mean/max/min, remove: all/surrounding, sample: simple/watershed\n",
    "NOTES = \"None\"  # \"mean-all-simple\"\n",
    "\n",
    "IOPATH = os.path.join(PATH_FILES, \"data_dump_\" + str(SCALE_PARAM) + \".dat\")\n",
    "\n",
    "cfg = Config(SCALE_PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ DATA\n",
    "with open(IOPATH, \"rb\") as infile:\n",
    "    data = pickle.load(infile)\n",
    "    (instance, instance_corr, start_inds, dest_inds) = data.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "\n",
    "* need range as broad as maxDist\n",
    "* more than two parts --> multiple sources problem --> here concentrated on two for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used right now\n",
    "N_PARTS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(instance[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_arr(arr, half_pixels, margin, axis=0):\n",
    "    if axis==0:\n",
    "        return arr[:half_pixels+int(margin), :], arr[half_pixels-int(margin):, :]\n",
    "    elif axis==1:\n",
    "        return arr[:, :half_pixels+int(margin)], arr[:, half_pixels-int(margin):]\n",
    "    else:\n",
    "        raise ValueError(\"wrong split axis, must be 0 or 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual start of script\n",
    "\n",
    "### Avoid axis pain by swapaxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_axis = np.argmax(np.absolute(start_inds-dest_inds))\n",
    "if split_axis==1:\n",
    "    instance = np.swapaxes(instance, 2,1)\n",
    "    instance_corr = np.swapaxes(instance_corr, 1, 0)\n",
    "    start_inds = np.flip(start_inds)\n",
    "    dest_inds = np.flip(dest_inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_patches(instance, instance_corr, pix_per_part, margin, padding):\n",
    "    two_insts = [(instance[:, :pix_per_part+margin+padding]).copy(), (instance[:, pix_per_part-margin-padding:]).copy()]\n",
    "    two_corrs = [(instance_corr[:pix_per_part+margin]).copy(), (instance_corr[pix_per_part-margin:]).copy()]\n",
    "    pad_zeros = np.zeros((padding, instance_corr.shape[1]))\n",
    "    two_corrs[0] = np.concatenate((two_corrs[0], pad_zeros), axis=0)\n",
    "    two_corrs[1] = np.concatenate((pad_zeros, two_corrs[1]), axis=0)\n",
    "    return two_insts, two_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_per_part = int(instance.shape[1]/2)\n",
    "margin = int(cfg.PYLON_DIST_MAX)\n",
    "padding = 20    \n",
    "two_insts, two_corrs = construct_patches(instance, instance_corr, pix_per_part, margin, padding)\n",
    "# two_insts = [(instance[:, :pix_per_part+margin]).copy(), (instance[:, pix_per_part-margin:]).copy()]\n",
    "# two_corrs = [(instance_corr[:pix_per_part+margin]).copy(), (instance_corr[pix_per_part-margin:]).copy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"check shapes:\", two_insts[0].shape, instance.shape, instance_corr.shape, two_corrs[0].shape, two_corrs[1].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set start and dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted_part = pix_per_part-margin-padding\n",
    "\n",
    "# if start is in first part and dest in second\n",
    "if start_inds[0] < dest_inds[0]:\n",
    "    start_points = [start_inds, dest_inds-[deleted_part, 0]]\n",
    "# if dest is in first part and start is in second one\n",
    "else:\n",
    "    start_points = [dest_inds, start_inds-[deleted_part, 0]]\n",
    "\n",
    "two_graphs = [None, None]\n",
    "\n",
    "print(deleted_part, start_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we got the correct point\n",
    "assert two_insts[1][2, start_points[1][0],start_points[1][1]] == instance[2, dest_inds[0], dest_inds[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct both graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all steps for both seperately\n",
    "vec = start_points[1]-start_points[0]  # start to dest vector\n",
    "\n",
    "for i in range(2):\n",
    "    graph = GRAPH_TYPE(\n",
    "        two_insts[i], two_corrs[i], graphtool=cfg.GTNX, verbose=cfg.VERBOSE\n",
    "    )\n",
    "\n",
    "    graph.set_edge_costs(\n",
    "        data.layer_classes, data.class_weights, angle_weight=cfg.ANGLE_WEIGHT\n",
    "    )\n",
    "    \n",
    "    # for the second graph, the shifts must be exactly the same as for the first one, just flipped\n",
    "    if i==1:\n",
    "        graph.angle_norm_factor = cfg.MAX_ANGLE_LG\n",
    "        graph.shifts = np.asarray(two_graphs[0].shifts) * (-1)\n",
    "        graph.shift_tuples = graph.shifts\n",
    "    else:\n",
    "        graph.set_shift(\n",
    "            cfg.PYLON_DIST_MIN,\n",
    "            cfg.PYLON_DIST_MAX,\n",
    "            vec,\n",
    "            cfg.MAX_ANGLE,\n",
    "            max_angle_lg=cfg.MAX_ANGLE_LG\n",
    "        )\n",
    "    \n",
    "    # add vertices\n",
    "    graph.add_nodes()\n",
    "    corridor = np.ones(two_corrs[i].shape) * 0.5 \n",
    "    graph.set_corridor(\n",
    "        corridor, start_points[i], start_points[i], factor_or_n_edges=1 # start_points[(i+1)%2],\n",
    "    )\n",
    "    graph.add_edges()\n",
    "    graph.sum_costs()\n",
    "    \n",
    "    # save the current graph\n",
    "    two_graphs[i] = graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For normal graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sp_from_preds(pred_map, curr_vertex, start_vertex):\n",
    "    path = [int(curr_vertex)]\n",
    "    counter = 0\n",
    "    while curr_vertex != start_vertex:\n",
    "        curr_vertex = pred_map[curr_vertex]\n",
    "        path.append(curr_vertex)\n",
    "        if counter > 100:\n",
    "            print(path)\n",
    "            raise RuntimeWarning(\"while loop for sp not terminating\")\n",
    "        counter += 1\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_tool.all import shortest_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_zones = [None, None]\n",
    "critical_zones[0] = two_graphs[0].pos2node[pix_per_part:-padding, :]\n",
    "critical_zones[1] = two_graphs[1].pos2node[padding:padding+margin, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(critical_zones[0])==margin\n",
    "summed = np.zeros(critical_zones[0].shape)\n",
    "pred_maps = []\n",
    "for i in range(2):\n",
    "    start_node_ind = two_graphs[i].pos2node[start_points[i][0], start_points[i][1]]\n",
    "    dist_map, pred_map = shortest_distance(\n",
    "                two_graphs[i].graph,\n",
    "                start_node_ind,\n",
    "                weights=two_graphs[i].weight,\n",
    "                negative_weights=True,\n",
    "                pred_map=True\n",
    "            )\n",
    "    pred_maps.append(pred_map)\n",
    "    for j in range(margin):\n",
    "        for k in range(summed.shape[1]):\n",
    "            node = critical_zones[i][j,k]\n",
    "            if node>=0:\n",
    "                summed[j,k] += dist_map[node]\n",
    "            else:\n",
    "                summed[j,k] += np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds0, inds1 = np.where(summed==np.min(summed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(inds0)==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct both paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nodes = [None, None]\n",
    "best_nodes[0] = two_graphs[0].pos2node[inds0[0]+pix_per_part, inds1[0]]\n",
    "best_nodes[1] = two_graphs[1].pos2node[inds0[0]+padding+margin, inds1[0]]\n",
    "\n",
    "concat_path = []\n",
    "for i in range(2):\n",
    "    start_node_ind = two_graphs[i].pos2node[start_points[i][0], start_points[i][1]]\n",
    "    vertices_path = get_sp_from_preds(pred_maps[i], best_nodes[i], start_node_ind)\n",
    "    path = np.array([(ind // two_graphs[i].y_len, ind % two_graphs[i].y_len) for ind in vertices_path])\n",
    "    ind = best_nodes[i]\n",
    "    print(ind // two_graphs[i].y_len, ind % two_graphs[i].y_len)\n",
    "    if i==0:\n",
    "        # -padding is not required because we only pad at the opposite side\n",
    "        path = np.flip(path, axis=0)\n",
    "    else:\n",
    "        path[:,0] = path[:,0]+deleted_part\n",
    "        path = path[1:]\n",
    "    concat_path.extend(path.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "concat_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For implicit LG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show distance surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(np.min(two_graphs[0].dists, axis=0))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(np.min(two_graphs[1].dists, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get overlapping part, the nodes that exist in both parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_zone0 = two_graphs[0].dists[:, pix_per_part:, :]\n",
    "critical_zone1 = two_graphs[1].dists[:, :int(margin), :]\n",
    "inst_zone = two_graphs[0].instance[pix_per_part:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_zone0.shape, critical_zone1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions to get sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _flat_ind_to_inds(flat_ind, arr_shape):\n",
    "    \"\"\"\n",
    "    Transforms an index of a flattened 3D array to its original coords\n",
    "    \"\"\"\n",
    "    _, len2, len3 = arr_shape\n",
    "    x1 = flat_ind // (len2 * len3)\n",
    "    x2 = (flat_ind % (len2 * len3)) // len3\n",
    "    x3 = (flat_ind % (len2 * len3)) % len3\n",
    "    return (x1, x2, x3)\n",
    "\n",
    "\n",
    "def get_sp_start_shift(\n",
    "    dists, dists_argmin, start_inds, dest_inds, shifts, min_shift\n",
    "):\n",
    "    if not np.any(dists[:, dest_inds[0], dest_inds[1]] < np.inf):\n",
    "        raise RuntimeWarning(\"empty path\")\n",
    "    curr_point = np.asarray(dest_inds)\n",
    "    my_path = [dest_inds]\n",
    "    # min_shift = np.argmin(dists[:, dest_inds[0], dest_inds[1]])\n",
    "    while np.any(curr_point - start_inds):\n",
    "        # print(curr_point)\n",
    "        new_point = curr_point - shifts[int(min_shift)]\n",
    "        min_shift = dists_argmin[int(min_shift), curr_point[0],\n",
    "                                 curr_point[1]]\n",
    "        my_path.append(new_point)\n",
    "        curr_point = new_point\n",
    "    return np.asarray(my_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best merge node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over all edges\n",
    "summed_dists = (\n",
    "    critical_zone0 + critical_zone1 - inst_zone\n",
    ")\n",
    "summed_dists[np.isnan(summed_dists)] = np.inf\n",
    "\n",
    "# get actual inds in smaller window\n",
    "best_path_ind = np.argmin(summed_dists.flatten())\n",
    "\n",
    "# get actual inds in smaller window\n",
    "best_shift, x, y = _flat_ind_to_inds(\n",
    "    best_path_ind, summed_dists.shape\n",
    ")\n",
    "\n",
    "print(best_path_ind, best_shift, x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct both paths from merge node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_ab = get_sp_start_shift(two_graphs[0].dists, two_graphs[0].dists_argmin, start_points[0], \n",
    "                          [x+pix_per_part-1, y], two_graphs[0].shifts, best_shift)\n",
    "path_cb = get_sp_start_shift(two_graphs[1].dists, two_graphs[1].dists_argmin, start_points[1],\n",
    "                          [x,y], two_graphs[1].shifts, best_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cb = np.array(path_cb)[1:]\n",
    "path_cb[:,0] = path_cb[:,0]+deleted_part\n",
    "\n",
    "together = np.concatenate(\n",
    "            (np.flip(np.array(path_ac), axis=0), path_cb),\n",
    "            axis=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check whether it is the correct path\n",
    "\n",
    "### Run for full instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = GRAPH_TYPE(\n",
    "    instance, instance_corr, graphtool=cfg.GTNX, verbose=cfg.VERBOSE\n",
    ")\n",
    "\n",
    "graph.set_edge_costs(\n",
    "    data.layer_classes, data.class_weights, angle_weight=cfg.ANGLE_WEIGHT\n",
    ")\n",
    "\n",
    "graph.set_shift(\n",
    "    cfg.PYLON_DIST_MIN,\n",
    "    cfg.PYLON_DIST_MAX,\n",
    "    dest_inds-start_inds,\n",
    "    cfg.MAX_ANGLE,\n",
    "    max_angle_lg=cfg.MAX_ANGLE_LG\n",
    ")\n",
    "\n",
    "# add vertices\n",
    "graph.add_nodes()\n",
    "\n",
    "corridor = np.ones(instance_corr.shape) * 0.5\n",
    "graph.set_corridor(\n",
    "    corridor, start_inds, dest_inds, factor_or_n_edges=1\n",
    ")\n",
    "print(\"1) set cost rest\")\n",
    "graph.add_edges()\n",
    "graph.sum_costs()\n",
    "start_v, target_v = graph.add_start_and_dest(start_inds, dest_inds)\n",
    "path, _,_ = graph.get_shortest_path(start_v, target_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(path)):\n",
    "    print(path[i], concat_path[i]) # together[i])#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together = np.array(concat_path)\n",
    "path = np.array(path)\n",
    "plt.plot(path[:,0], path[:,1])\n",
    "plt.plot(together[:,0], together[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
