{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from types import SimpleNamespace\n",
    "from collections import defaultdict\n",
    "from numba import jit\n",
    "\n",
    "# utils imports\n",
    "from power_planner.data_reader import DataReader\n",
    "from power_planner import graphs\n",
    "from power_planner.plotting import plot_path_costs, plot_pipeline_paths, plot_path, plot_k_sp\n",
    "from power_planner.utils.utils import get_distance_surface, time_test_csv, compute_pylon_dists\n",
    "from power_planner.utils.utils_ksp import KspUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH_FILES = \"../data\"\n",
    "\n",
    "# DEFINE CONFIGURATION\n",
    "ID = \"w_ksp_5\"  # str(round(time.time() / 60))[-5:]\n",
    "\n",
    "OUT_PATH = \"outputs/path_\" + ID\n",
    "SCALE_PARAM = 5  # args.scale\n",
    "# normal graph pipeline\n",
    "# PIPELINE = [(2, 50), (1, 0)]  # [(1, 0)]  # [(4, 80), (2, 50), (1, 0)]  #\n",
    "# random graph pipeline\n",
    "PIPELINE = [(1, 0)]  # [(0.9, 40), (0, 0)]\n",
    "\n",
    "GRAPH_TYPE = graphs.ImplicitKSP\n",
    "# LineGraph, WeightedGraph, RandomWeightedGraph, RandomLineGraph, PowerBF\n",
    "# TwoPowerBF, WeightedKSP\n",
    "print(\"graph type:\", GRAPH_TYPE)\n",
    "# summarize: mean/max/min, remove: all/surrounding, sample: simple/watershed\n",
    "NOTES = \"None\"  # \"mean-all-simple\"\n",
    "\n",
    "IOPATH = os.path.join(PATH_FILES, \"belgiumlarge_dump_\" + str(SCALE_PARAM) + \".dat\")\n",
    "\n",
    "with open(\"../config.json\", \"r\") as infile:\n",
    "    cfg_dict = json.load(infile)  # Config(SCALE_PARAM)\n",
    "    cfg = SimpleNamespace(**cfg_dict)\n",
    "    cfg.PYLON_DIST_MIN, cfg.PYLON_DIST_MAX = compute_pylon_dists(\n",
    "        cfg.PYLON_DIST_MIN, cfg.PYLON_DIST_MAX, cfg.RASTER, SCALE_PARAM\n",
    "    )\n",
    "    \n",
    "# READ DATA\n",
    "with open(IOPATH, \"rb\") as infile:\n",
    "    data = pickle.load(infile)\n",
    "    (instance, instance_corr, start_inds, dest_inds) = data.data\n",
    "    \n",
    "tic1 = time.time()\n",
    "graph = GRAPH_TYPE(\n",
    "    instance, instance_corr, graphtool=cfg.GTNX, verbose=cfg.VERBOSE\n",
    ")\n",
    "\n",
    "graph.set_shift(\n",
    "    cfg.PYLON_DIST_MIN,\n",
    "    cfg.PYLON_DIST_MAX,\n",
    "    dest_inds - start_inds,\n",
    "    cfg.MAX_ANGLE,\n",
    "    max_angle_lg=cfg.MAX_ANGLE_LG\n",
    ")\n",
    "corridor = np.ones(instance_corr.shape) * 0.5  # start with all\n",
    "\n",
    "graph.set_corridor(corridor, start_inds, dest_inds, factor_or_n_edges=1)\n",
    "\n",
    "graph.set_edge_costs(\n",
    "    data.layer_classes, data.class_weights, angle_weight= 0.1 # cfg.ANGLE_WEIGHT\n",
    ")\n",
    "# add vertices\n",
    "graph.add_nodes()\n",
    "\n",
    "# START PIPELINE\n",
    "tic = time.time()\n",
    "print(\"1) set cost rest\")\n",
    "graph.add_edges(edge_weight=0.33)\n",
    "print(\"2) added edges\", graph.n_edges)\n",
    "print(\"number of vertices:\", graph.n_nodes)\n",
    "\n",
    "# weighted sum of all costs\n",
    "graph.sum_costs()\n",
    "source_v, target_v = graph.add_start_and_dest(start_inds, dest_inds)\n",
    "print(\"3) summed cost, get source and dest\")\n",
    "# get actual best path\n",
    "path, path_costs, cost_sum = graph.get_shortest_path(source_v, target_v)\n",
    "print(\"4) shortest path\")\n",
    "print(time.time()-tic1)\n",
    "\n",
    "graph.get_shortest_path_tree(source_v, target_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_min_node_dists(self):\n",
    "    best_paths = [self.best_path]\n",
    "    tuple_path = [tuple(p) for p in self.best_path]\n",
    "    sp_set = set(tuple_path)\n",
    "    # sum both dists_ab and dists_ba, subtract inst because counted twice\n",
    "    summed_dists = (self.dists + self.dists_ba - self.instance - self.edge_cost)\n",
    "    # mins along outgoing edges\n",
    "    min_node_dists = np.min(summed_dists, axis=0)\n",
    "    min_shift_dists = np.argmin(summed_dists, axis=0)\n",
    "    # argsort\n",
    "    v_shortest = np.argsort(min_node_dists.flatten())\n",
    "    return min_node_dists, v_shortest, min_shift_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_node_dists, v_shortest, min_shift_dists = compute_min_node_dists(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(min_node_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def currently_implemented(self, source, dest, k, overlap=0.5):\n",
    "    tic = time.time()\n",
    "    ksp = self.find_ksp(source, dest, k, overlap=overlap)\n",
    "    toc = time.time()\n",
    "    return ksp, toc-tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucl_max(self, source, dest, k, overlap=8):\n",
    "    tic = time.time()\n",
    "    min_node_dists, v_shortest, min_shift_dists = compute_min_node_dists(self)  \n",
    "    best_paths = [self.best_path]\n",
    "    tup_path = [np.array(p) for p in self.best_path]\n",
    "    # sp_set = set(tuple_path)\n",
    "    sorted_dists = min_node_dists.flatten()[v_shortest]\n",
    "    _, arr_len  = min_node_dists.shape\n",
    "\n",
    "    expanded = 0\n",
    "    for j in range(len(v_shortest)):\n",
    "        if sorted_dists[j]==sorted_dists[j-1]:\n",
    "            # we always check a path only if it is the x-th appearance\n",
    "            # print(counter)\n",
    "            continue\n",
    "         \n",
    "        # counter large enough --> expand\n",
    "        (x2, x3) = v_shortest[j]//arr_len, v_shortest[j]%arr_len\n",
    "        \n",
    "        # compute eucledian distances\n",
    "        eucl_dist = [np.linalg.norm(np.array([x2,x3]) - tup) for tup in tup_path]\n",
    "        if np.min(eucl_dist)>overlap:\n",
    "            expanded += 1\n",
    "            x1 = min_shift_dists[x2,x3]\n",
    "            if self.dists_ba[x1, x2, x3] == 0:\n",
    "                # print(\"inc edge to dest\")\n",
    "                # = 0 for inc edges of dest_inds (init of dists_ba)\n",
    "                continue\n",
    "            vertices_path = self._combined_paths(\n",
    "                source, dest, x1, [x2, x3]\n",
    "            )\n",
    "            # assert np.any([np.array([x2,x3])==v for v in vertices_path])\n",
    "            best_paths.append(vertices_path)\n",
    "            for v in vertices_path:\n",
    "                v_in = [np.all(v==elem) for elem in tup_path]\n",
    "                if not np.any(v_in):\n",
    "                    tup_path.append(v)\n",
    "\n",
    "            if len(best_paths) >= k:\n",
    "                print(j, \"expanded\", expanded)\n",
    "                break\n",
    "    toc = time.time()\n",
    "    ksp = [self.transform_path(path) for path in best_paths]\n",
    "    return ksp, toc-tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_max_cost(self, cost_thresh):\n",
    "    # set maximum on costs\n",
    "    best_path_cells, _, best_cost = self.transform_path(self.best_path)\n",
    "    correction = 0.5 * (\n",
    "        self.instance[tuple(best_path_cells[0])] +\n",
    "        self.instance[tuple(best_path_cells[-1])]\n",
    "    )\n",
    "    print(best_cost, max_cost * best_c)\n",
    "    assert np.isclose(best_cost, cost_thresh + correction)\n",
    "    max_costs = best_cost * cost_thresh - correction\n",
    "    return max_costs\n",
    "    \n",
    "    max_costs = best_cost * cost_thresh - correction\n",
    "\n",
    "def most_diverse(self, source, dest, k, cost_thresh, dist_mode=\"jaccard\"):\n",
    "    tic = time.time()\n",
    "    min_node_dists, v_shortest, min_shift_dists = compute_min_node_dists(self)\n",
    "    sorted_dists = min_node_dists.flatten()[v_shortest]\n",
    "    best_path_cells, _, best_cost = self.transform_path(self.best_path)\n",
    "    max_cost = best_cost * cost_thresh # set_max_cost(self, sorted_dists[0])\n",
    "    _, arr_len = min_node_dists.shape\n",
    "    collected_path = []\n",
    "    \n",
    "    tic1 = time.time()\n",
    "    for j in range(len(v_shortest)):\n",
    "        if sorted_dists[j]==sorted_dists[j-1]:\n",
    "            continue\n",
    "            \n",
    "        if sorted_dists[j] > max_cost:\n",
    "            break\n",
    "            \n",
    "         # counter large enough --> expand\n",
    "        (x2, x3) = v_shortest[j]//arr_len, v_shortest[j]%arr_len\n",
    "        x1 = min_shift_dists[x2,x3]\n",
    "        if self.dists_ba[x1, x2, x3] == 0:\n",
    "            # print(\"inc edge to dest\")\n",
    "            # = 0 for inc edges of dest_inds (init of dists_ba)\n",
    "            continue\n",
    "        vertices_path = self._combined_paths(\n",
    "            source, dest, x1, [x2, x3]\n",
    "        )\n",
    "        collected_path.append(vertices_path)\n",
    "        \n",
    "    print(\"collect paths time:\", round(time.time()-tic1, 3))\n",
    "    \n",
    "    tic2 = time.time()\n",
    "        \n",
    "    dists = KspUtils.pairwise_dists(collected_path, mode=dist_mode)\n",
    "    \n",
    "    print(\"Pairwise dist time:\", round(time.time()-tic2, 3))\n",
    "    \n",
    "    tic3 = time.time()\n",
    "    \n",
    "    # find the two which are most diverse (following 2-approx)\n",
    "    max_dist_pair = np.argmax(dists)\n",
    "    div_ksp = [max_dist_pair // len(dists), max_dist_pair % len(dists)]\n",
    "    # greedily add the others\n",
    "    for _ in range(k - 2):\n",
    "        min_dists = []\n",
    "        for i in range(len(dists)):\n",
    "            min_dists.append(np.min([dists[i, div_ksp]]))\n",
    "        div_ksp.append(np.argmax(min_dists))\n",
    "        \n",
    "    print(\"final argmax paths time:\", round(time.time()-tic3, 3))\n",
    "    \n",
    "    ksp = [self.transform_path(collected_path[p]) for p in div_ksp]\n",
    "    print(len(collected_path))\n",
    "    toc = time.time()\n",
    "    return ksp, toc-tic\n",
    "\n",
    "def most_diverse_jaccard(self, source, dest, k, cost_thresh):\n",
    "    return most_diverse(self, source, dest, k, cost_thresh, dist_mode=\"jaccard\")\n",
    "def most_diverse_eucl_max(self, source, dest, k, cost_thresh):\n",
    "    return most_diverse(self, source, dest, k, cost_thresh, dist_mode=\"eucl_max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def laplace(self, source, dest, k, radius = 20, cost_add=0.005):\n",
    "    tic = time.time()\n",
    "    best_paths = [self.best_path]\n",
    "    min_node_dists, v_shortest, min_shift_dists = compute_min_node_dists(self)\n",
    "    # print(min_node_dists)\n",
    "    best_path_cells, _, best_cost = self.transform_path(self.best_path)\n",
    "    factor = best_cost * cost_add\n",
    "    print(factor)\n",
    "    _, arr_len = min_node_dists.shape\n",
    "    for _ in range(k-1):\n",
    "        # set the already used vertices to inf (not use anymore for selected vertex)\n",
    "        for b in best_paths[-1]:\n",
    "            min_node_dists[tuple(b)] = np.inf\n",
    "        # add in corridor / distribution\n",
    "        corridor = get_distance_surface(\n",
    "                min_node_dists.shape,\n",
    "                best_paths,\n",
    "                mode=\"dilation\",\n",
    "                n_dilate=radius\n",
    "            )\n",
    "        corridor = corridor / np.max(corridor)\n",
    "        min_node_dists = min_node_dists + corridor * factor\n",
    "        # get min vertex\n",
    "        current_best = np.nanargmin(min_node_dists.flatten())\n",
    "        (x2, x3) = current_best//arr_len, current_best%arr_len\n",
    "        # print(x2, x3, arr_len, current_best)\n",
    "        x1 = min_shift_dists[x2,x3]\n",
    "        if self.dists_ba[x1, x2, x3] == 0:\n",
    "            k+=1\n",
    "            continue\n",
    "        # compute and add\n",
    "        vertices_path = self._combined_paths(\n",
    "            source, dest, x1, [x2, x3]\n",
    "        )\n",
    "        best_paths.append(vertices_path)\n",
    "    # output\n",
    "    ksp = [self.transform_path(p) for p in best_paths]\n",
    "    toc = time.time()\n",
    "    return ksp, toc-tic\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ksp, toc = laplace(graph, start_inds, dest_inds, 5, 30)\n",
    "print(tic)\n",
    "plot_k_sp(ksp, graph.instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sim(ksp, metric):\n",
    "    \"\"\"\n",
    "    evaluate ksp diversity according to several metric\n",
    "    \"\"\"\n",
    "    ksp_paths = [k[0] for k in ksp]\n",
    "    out_diversity = [] # np.zeros((3,2))\n",
    "    # for k, metric in enumerate([\"eucl_mean\", \"eucl_max\", \"jaccard\"]):\n",
    "    divs = []\n",
    "    for i in range(len(ksp_paths)):\n",
    "        for j in range(i+1,len(ksp_paths)):\n",
    "            divs.append(KspUtils.path_distance(ksp_paths[i],ksp_paths[j], mode=metric))\n",
    "        # out_diversity.append(np.mean(divs))\n",
    "        # out_diversity[k,1] = np.sum(divs)\n",
    "    # return out_diversity\n",
    "    return np.mean(divs)\n",
    "\n",
    "def evaluate_cost(ksp):\n",
    "    # ksp_path_costs = [k[1] for k in ksp]\n",
    "    # for p_cost in ksp_path_costs:\n",
    "    #     p = np.asarray(p_cost)\n",
    "    #     c_m = np.mean(np.sum(p,axis=1))\n",
    "    ksp_all_costs = [k[2] for k in ksp]\n",
    "    return [np.sum(ksp_all_costs), np.max(ksp_all_costs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_dict = defaultdict(list)\n",
    "metrics = [\"eucl_mean\", \"eucl_max\", \"jaccard\"]\n",
    "\n",
    "func_eval = [eucl_max, eucl_max, eucl_max, eucl_max, \n",
    "             currently_implemented,currently_implemented,currently_implemented,currently_implemented, \n",
    "             # most_diverse_jaccard, most_diverse_jaccard, most_diverse_eucl_max, most_diverse_eucl_max, \n",
    "             laplace, laplace, laplace, laplace]\n",
    "names = [\"vertex eucl max\", \"vertex eucl max\", \"vertex eucl max\",\"vertex eucl max\", \n",
    "         \"greedy max set\", \"greedy max set\", \"greedy max set\", \"greedy max set\",\n",
    "         # \"diverse jaccard\", \"diverse jaccard\", \"diverse eucl max\", \"diverse eucl max\",\n",
    "         \"corridor\", \"corridor\", \"corridor\", \"corridor\"]\n",
    "thresh_eval = [8, 12, 14, 18, \n",
    "               0.4, 0.6, 0.8, 1.0,\n",
    "               # 1.01, 1.005, 1.0025, 1.005,\n",
    "               10, 20, 40, 60]\n",
    "assert len(func_eval)==len(names)\n",
    "assert len(names)==len(thresh_eval)\n",
    "\n",
    "all_ksps = []\n",
    "for name, func, param in zip(names, func_eval, thresh_eval):\n",
    "    ksp, tic = func(graph, start_inds, dest_inds, 5, param)\n",
    "    all_ksps.append(ksp)\n",
    "    res_dict[\"name\"].append(name)\n",
    "    res_dict[\"threshold\"].append(param)\n",
    "    res_dict[\"times\"].append(tic)\n",
    "    for m in metrics:\n",
    "        res_dict[m+\"_distance\"].append(evaluate_sim(ksp, m))\n",
    "    cost_sum, cost_max = evaluate_cost(ksp)\n",
    "    res_dict[\"cost_sum\"].append(cost_sum)\n",
    "    res_dict[\"cost_max\"].append(cost_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"corridor01\"\n",
    "param = 5\n",
    "\n",
    "# for name, func, param in zip(names, func_eval, thresh_eval):\n",
    "ksp, tic = laplace(graph, start_inds, dest_inds, 5, param, cost_add=0.01)\n",
    "all_ksps.append(ksp)\n",
    "res_dict[\"name\"].append(name)\n",
    "res_dict[\"threshold\"].append(param)\n",
    "res_dict[\"times\"].append(tic)\n",
    "for m in metrics:\n",
    "    res_dict[m+\"_distance\"].append(evaluate_sim(ksp, m))\n",
    "cost_sum, cost_max = evaluate_cost(ksp)\n",
    "res_dict[\"cost_sum\"].append(cost_sum)\n",
    "res_dict[\"cost_max\"].append(cost_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ksp_compare = pd.DataFrame(res_dict, index=res_dict[\"name\"])\n",
    "df_ksp_compare[\"extended_names\"] = [n+\"_\"+str(int(t)) for n, t in zip(res_dict[\"name\"], res_dict[\"threshold\"])]\n",
    "np.around(df_ksp_compare, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ksp_compare.to_csv(\"compare_diverse_ksp_blarge_res5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"compare_diverse_ksp_blarge_res5.dat\", \"wb\") as outfile:\n",
    "    pickle.dump(all_ksps, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot pareto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "chosen_metric = \"eucl_max_distance\"\n",
    "for name, grouped in df_ksp_compare.groupby(\"name\"):\n",
    "    plt.scatter(grouped[chosen_metric], grouped[\"cost_sum\"], label = name, s=30)\n",
    "plt.legend(fontsize=15)\n",
    "plt.xlabel(chosen_metric, fontsize=15)\n",
    "plt.ylabel(\"sum of costs\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only some chosen alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_names = [\"greedy max set_1\", \"vertex eucl max_6\", \"vertex eucl max_8\", \"corridor01_20\", \"corridor01_5\",\"diverse eucl max_1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_ksp_compare.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_inds = test[\"extended_names\"].isin(take_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_smaller72 = test[take_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_smaller72[\"explanation\"] = [\"Greedily add the next VERTEX with eucl distance > 300m to all previous paths\",\n",
    "                                \"Greedily add the next VERTEX with eucl distance > 500m to all previous paths\",\n",
    "                                \"Greedily add the next shortest path with less than x% vertices already used in previous paths\",\n",
    "                                \"P-dispersion - find k most diverse paths (Yen-Hausdorff) out of all paths with cost < 1.01 * best path cost\",\n",
    "                                \"Add penalty x in distribution fashion to the cost surface in corridor of radius 20 around the previous paths\",\n",
    "                                \"Add penalty x in distribution fashion to the cost surface in corridor of radius 5 around the previous paths\"\n",
    "                                ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = np.around(test_smaller72[[\"extended_names\", \"explanation\", \"times\", \"eucl_max_distance\", \"jaccard_distance\", \"cost_sum\"]], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_several_ksp(all_ksp, ksp_names, inst, out_path=None):\n",
    "    \"\"\"\n",
    "    Plot k shortest paths on the instance\n",
    "    Arguments:\n",
    "        ksp: list of infos for the k shortest path: for each path, the first\n",
    "            entry is the path itself, the second the costs array, the third\n",
    "            the cost sum\n",
    "        inst: instance to plot on\n",
    "    \"\"\"\n",
    "    cols = [\"purple\", \"orange\", \"yellow\", \"red\", \"blue\", \"black\", \"green\"][:len(ksp_names)]\n",
    "    \n",
    "    # plot main image (cost surface)\n",
    "    plt.figure(figsize=(10, 20))\n",
    "    plt.imshow(np.swapaxes(inst, 1, 0))\n",
    "    \n",
    "    # get relevant information\n",
    "    for ksp, names, colour in zip(all_ksp, ksp_names, cols):\n",
    "        paths = [k[0] for k in ksp]\n",
    "        # iterate over k shortest paths\n",
    "        for i, path in enumerate(paths):\n",
    "            path = np.asarray(path)\n",
    "            plt.plot(\n",
    "                path[:, 0], path[:, 1], label=names,c=colour, linewidth=3\n",
    "            )\n",
    "    # plot and save\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    leg = plt.legend(by_label.values(), by_label.keys(), fontsize=15)\n",
    "\n",
    "    leg.set_title('Costs', prop={'size': 15})\n",
    "    plt.axis(\"off\")\n",
    "    if out_path is not None:\n",
    "        plt.savefig(out_path + \"_ksp.pdf\")\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "def plot_k_sp(ksp, inst, out_path=None):\n",
    "    \"\"\"\n",
    "    Plot k shortest paths on the instance\n",
    "    Arguments:\n",
    "        ksp: list of infos for the k shortest path: for each path, the first\n",
    "            entry is the path itself, the second the costs array, the third\n",
    "            the cost sum\n",
    "        inst: instance to plot on\n",
    "    \"\"\"\n",
    "    # get relevant information\n",
    "    costs = [k[2] for k in ksp]\n",
    "    paths = [k[0] for k in ksp]\n",
    "\n",
    "    # plot main image (cost surface)\n",
    "    plt.figure(figsize=(10, 20))\n",
    "    plt.imshow(np.swapaxes(inst, 1, 0))\n",
    "    # iterate over k shortest paths\n",
    "    for i, path in enumerate(paths):\n",
    "        path = np.asarray(path)\n",
    "        plt.scatter(\n",
    "            path[:, 0], path[:, 1], label=str(round(costs[i], 2)), s=50\n",
    "        )\n",
    "    # plot and save\n",
    "    leg = plt.legend(fontsize=15)\n",
    "    leg.set_title('Costs', prop={'size': 15})\n",
    "    plt.title(out_path.split(\"/\")[1], fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.axis(\"off\")\n",
    "    if out_path is not None:\n",
    "        plt.savefig(out_path + \"_ksp.png\")\n",
    "    else:\n",
    "        plt.show()\n",
    "# take_ksps = [all_ksps[i] for i in range(len(all_ksps)) if take_inds.values[i]]\n",
    "# plot_several_ksp(take_ksps, np.asarray(df_ksp_compare[\"extended_names\"])[take_inds], graph.instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (_, row) in enumerate(df_ksp_compare.iterrows()):\n",
    "    title = row[\"name\"] + \" with threshold \" +str(row[\"threshold\"]) + \" Runtime: \"+str(round(row[\"times\"],2))\n",
    "    plot_k_sp(all_ksps[i], graph.instance, \"ksp_plots/large_\"+title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksps_set = collect_ksp_results(currently_implemented, [0.4,0.5,0.6, 0.65, 0.7,0.8, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksps_eucl_max.extend(collect_ksp_results(eucl_max, [14, 16, 18]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksps_distance = collect_ksp_results(most_diverse_jaccard, [1.005, 1.01, 1.015])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksps_diverse_eucl = collect_ksp_results(most_diverse_eucl_max, [1.005, 1.01, 1.015])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ksps_distance.append(most_diverse_jaccard(graph, start_inds, dest_inds, K_PATHS, 1.018)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksp_laplace_new = collect_ksp_results(laplace, [10,15,20,25,30,35,40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksp_laplace = collect_ksp_results(laplace, [0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005, 0.01,0.05, 0.075])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_ksps = [ksps_set, ksps_eucl_max, ksps_distance, ksp_laplace, ksps_diverse_eucl]\n",
    "to_compare_names = [\"greedy jaccard\", \"greedy eucl max\", \"diverse jaccard\", \"corridor\", \"diverse eucl max\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for i, out_ksp in enumerate(collected_ksps):\n",
    "    res = []\n",
    "    for ksp in out_ksp:\n",
    "        cost, dist = ksp_evaluate(ksp)\n",
    "        cost_normed = cost - cost_sum * K_PATHS\n",
    "        res.append([cost_normed, -dist])\n",
    "    res = np.array(res)\n",
    "    plt.plot(res[:,0], res[:,1], label = to_compare_names[i])\n",
    "plt.title(\"comparison of ksp algorithms\")\n",
    "plt.xlabel(\"sum of costs\")\n",
    "plt.ylabel(\"similarity\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ksp_evaluate(ksp):\n",
    "    # METRIC 1: just sum of all pairwise maximum pylonwise distance \n",
    "    costs = [k[2] for k in ksp]\n",
    "    paths = [k[0] for k in ksp]\n",
    "    \n",
    "    inters = []\n",
    "    for i in range(len(paths)):\n",
    "        p1 = paths[i]\n",
    "        for j in range(i+1,len(paths)):\n",
    "            p2 = paths[j]\n",
    "            norms = []\n",
    "            for k in range(min([len(p1), len(p2)])):\n",
    "                norms.append(np.linalg.norm(np.array(p1[k])-np.array(p2[k])))\n",
    "            inters.append(np.max(norms))\n",
    "    return np.sum(costs), np.sum(inters)\n",
    "\n",
    "def collect_ksp_results(func_to_eval, appropriate_thresholds):\n",
    "    out_ksps = []\n",
    "    for thresh in appropriate_thresholds:\n",
    "        ksp, time_new = func_to_eval(graph, start_inds, dest_inds, K_PATHS, thresh) \n",
    "        out_ksps.append(ksp)\n",
    "    return out_ksps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance KSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from power_planner.utils.utils_constraints import ConstraintUtils\n",
    "from power_planner.utils.utils_costs import CostUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_costs(self, path):\n",
    "    ang_costs = ConstraintUtils.compute_angle_costs(\n",
    "        path, self.angle_norm_factor\n",
    "    )\n",
    "    # edge_costs = CostUtils.compute_edge_costs(path, self.edge_inst)\n",
    "    normal_cost = [self.instance[i,j] for (i,j) in path]\n",
    "    return [normal_cost[i] + ang_costs[i] for i in range(len(normal_cost))]\n",
    "\n",
    "def var_ksp(self, source, dest, k, thresh = 0.995, cost_thresh=1.05):\n",
    "    tic = time.time()\n",
    "    min_node_dists, v_shortest, min_shift_dists = compute_min_node_dists(self)  \n",
    "    best_paths = [self.best_path]\n",
    "    tup_path = [np.array(p) for p in self.best_path]\n",
    "    # sp_set = set(tuple_path)\n",
    "    sorted_dists = min_node_dists.flatten()[v_shortest]\n",
    "    _, arr_len  = min_node_dists.shape\n",
    "    \n",
    "    # add the best path factors\n",
    "    path_costs = np.asarray(self.transform_path(self.best_path)[1])\n",
    "    cost = np.dot(\n",
    "        path_costs, self.cost_weights\n",
    "    )\n",
    "    current_best_mean = np.mean(cost)\n",
    "    current_best_variance = np.std(cost)\n",
    "    stds, means, sums = [np.std(cost)], [np.mean(cost)], [np.sum(cost)]\n",
    "    best_sum = np.sum(cost)\n",
    "    # iterate and add\n",
    "\n",
    "    expanded = 0\n",
    "    for j in range(len(v_shortest)):\n",
    "        if np.isclose(sorted_dists[j], sorted_dists[j-1]):\n",
    "            # we always check a path only if it is the x-th appearance\n",
    "            # print(counter)\n",
    "            continue\n",
    "         \n",
    "        # counter large enough --> expand\n",
    "        (x2, x3) = v_shortest[j]//arr_len, v_shortest[j]%arr_len\n",
    "        \n",
    "        # compute eucledian distances\n",
    "        x1 = min_shift_dists[x2,x3]\n",
    "        if self.dists_ba[x1, x2, x3] == 0:\n",
    "            # print(\"inc edge to dest\")\n",
    "            # = 0 for inc edges of dest_inds (init of dists_ba)\n",
    "            continue\n",
    "        vertices_path = self._combined_paths(\n",
    "            source, dest, x1, [x2, x3]\n",
    "        )\n",
    "        # Compute path costs\n",
    "        path_costs = np.asarray(self.transform_path(vertices_path)[1])\n",
    "        cost = np.dot(\n",
    "            path_costs, self.cost_weights\n",
    "        ) \n",
    "        m, std, s = np.mean(cost), np.std(cost), np.sum(cost)\n",
    "        if s>cost_thresh*best_sum:\n",
    "            break\n",
    "        # update if variance or mean are exceptional\n",
    "        if std<thresh*current_best_variance: #  or m < thresh * current_best_mean:\n",
    "            # print(m, std)\n",
    "            means.append(m)\n",
    "            stds.append(std)\n",
    "            sums.append(s)\n",
    "            current_best_mean = m\n",
    "            current_best_variance = std\n",
    "            best_paths.append(vertices_path)\n",
    "    toc = time.time()\n",
    "    ksp = [self.transform_path(path) for path in best_paths]\n",
    "    plot_indicators = (means, stds, sums)\n",
    "    return plot_indicators, ksp, toc-tic\n",
    "plot_indicators, var_ksp, tics = var_ksp(graph, start_inds, dest_inds, 5)\n",
    "means, stds, sums = plot_indicators\n",
    "# print(np.vstack([means, stds]))\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(sums, stds, label=\"std\")\n",
    "plt.xlabel(\"sum of cost\", fontsize=15)\n",
    "plt.ylabel(\"cost standard deviation\", fontsize=15)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(sums, means, label=\"mean\")\n",
    "plt.xlabel(\"sum of cost\", fontsize=15)\n",
    "plt.ylabel(\"cost mean\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "n = 100\n",
    "\n",
    "# For each set of style and range settings, plot n random points in the box\n",
    "# defined by x in [23, 32], y in [0, 100], z in [zlow, zhigh].\n",
    "ax.scatter(sums, means, stds, marker=\"o\", s=30)\n",
    "\n",
    "ax.set_xlabel('Sum', fontsize=20)\n",
    "ax.set_ylabel('Mean', fontsize=20)\n",
    "ax.set_zlabel('Std', fontsize=20)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_k_sp(var_ksp, graph.instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_curr = 20\n",
    "required_dist = 15\n",
    "dist_range = 4\n",
    "sim = 0\n",
    "while abs(sim- required_dist)>dist_range:\n",
    "    ksp, toc = laplace(graph, start_inds, dest_inds, 5, radius=rad_curr, cost_add=0.01)\n",
    "    # print(\"Sim:\", evaluate_sim(ksp, \"eucl_max\"))\n",
    "    sim = evaluate_sim(ksp, \"eucl_max\") \n",
    "    # if sim > required_dist:\n",
    "    rad_curr *= required_dist/sim\n",
    "    rad_curr = int(rad_curr)\n",
    "    print(sim, required_dist, rad_curr)\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ksps = collect_ksp_results(most_diverse_jaccard, [1.005, 1.01, 1.015])\n",
    "res_func = []\n",
    "for ksp in out_ksps:\n",
    "    cost, dist = ksp_evaluate(ksp)\n",
    "    cost_normed = cost - cost_sum * K_PATHS\n",
    "    res_func.append([cost_normed, - dist])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
